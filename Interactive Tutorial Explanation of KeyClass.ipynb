{"cells":[{"cell_type":"markdown","metadata":{"id":"Pttu7dqxFqcC"},"source":["\n","\n","# A Revised Interactive KeyClass Tutorial: Text Classification with Label-Descriptions Only\n","\n","\n","<hr>\n","\n","***By:*** Laxmi Vijayan, Aganze Mihigo   \n","\n","***Based On:*** Classifying Unstructured Clinical Notes via Automatic Weak Supervision\n","**Authors:** Arnab Dey, Chufan Gao, Mononito Goswami, correspondence to &lt;mgoswami@andrew.cmu.edu&gt;\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OtodKiqhFqcD"},"source":["# 1. Introduction\n","\n","## 1.1 Problem Background & Motivation\n","\n","The accuracy of International Classification of Diseases (ICD) codes is paramount in the healthcare sector for two main reasons:\n","\n","1. These codes are integral to standardized billing practices so providers are reimbursed correctly and efficiently for the services they provide <sup><a href=\"#references\"><b>1</b></a></sup>.\n","2. ICD codes are crucial in epidemiological studies, where they help in tracking and analyzing the prevalence and incidence of diseases across different populations and geographies.<sup><a href=\"#references\"><b>2</b></a>,</sup><sup><a href=\"#references\"><b>3</b></a>,</sup><sup><a href=\"#references\"><b>4</b></a></sup>\n","\n","The assignment of ICD codes is determined through the analysis of Electronic Health Records (EHRs) which are comprehensive, patient-centered records that are digital versions of a patient's paper chart and track a patient’s trajectory through the healthcare system <sup><a href=\"#references\"><b>1</b></a></sup>. These records include:\n","1. Detailed medical histories\n","2. Diagnoses Information\n","3. Procedures\n","4. Medications Information.\n","\n","However, the data captured in EHRs can often be unstructured and comprised of medical jargon, making the assignment of ICD codes a labor-intensive process. Consequently, healthcare providers frequently depend on trained coders or third-party vendors. This process is **expensive**, **labor-intensive**, and **prone to errors**<sup><a href=\"#references\"><b>1</b></a>,</sup><sup><a href=\"#references\"><b>5</b></a>,</sup><sup><a href=\"#references\"><b>6</b></a></sup> due to the subjective interpretation of text and the ever-evolving nature of medical nomenclature and coding systems.\n","\n","Given the broad impact of ICD codes within the healthcare sector, there is a pressing demand for **accuracy** and **efficiency**, which has spurred interest in leveraging machine learning (ML) technologies to automate the coding process. These systems can potentially reduce the time and cost associated with manual coding and improve accuracy by consistently applying the same rules to the available data, thereby minimizing human error.\n","\n","However, conventional ML approaches depend heavily on large volumes of manually labeled data, which are still costly and labor-intensive<sup><a href=\"#references\"><b>9</b></a>,</sup><sup><a href=\"#references\"><b>10</b></a></sup>. This problem is exacerbated twofold by the frequent updates to the ICD, which are not necessarily compatible with previous versions, and by the large variability in the existing labeled diagnostic data as a result of institutional processes or the clinical diagnostic practices of the physicians <sup><a href=\"#references\"><b>1</b></a>,</sup><sup><a href=\"#references\"><b>7</b></a>,</sup><sup><a href=\"#references\"><b>8</b></a></sup>.\n","\n","The need for a reliable, generalizable, cost- and time-effective automated classification system is clear.\n","\n","## 1.2 Classifying Unstructured Clinical Notes via Automatic Weak Supervision\n","\n","In the paper \"Classifying Unstructured Clinical Notes via Automatic Weak Supervision,\" <sup><a href=\"#references\"><b>10</b></a></sup> the authors present a novel framework for text classification, specifically focusing on assigning International Classification of Diseases (ICD) codes to unstructured clinical notes without the need for manually labeled data. This framework, named KeyClass, utilizes a general weakly supervised learning approach, leveraging the linguistic domain knowledge embedded in pre-trained language models and employing a data programming methodology.\n","\n","### 1.2.1 Innovations and Effectiveness\n","\n","KeyClass introduces several innovative approaches:\n","1. **Interpretable Weak Supervision Sources**: It automatically extracts weak supervision sources, such as keywords and phrases from class-label descriptions, allowing the model to learn from these inputs without the need for a human-labeled training set.\n","2. **Utilization of Pre-trained Language Models**: By integrating pre-trained language models, KeyClass harnesses extensive linguistic knowledge, facilitating the accurate classification of medical terms and phrases found in clinical notes.\n","3. **Data Programming Integration**: KeyClass employs data programming to generate probabilistic labels for training data, significantly reducing the reliance on manually labeled datasets.\n","\n","### 1.2.2 Performance\n","KeyClass demonstrated strong performance across multiple datasets, particularly the MIMIC-III database, where it was tasked with assigning ICD-9 codes to medical notes. It performed comparably to more traditional supervised learning methods such as FasTag <sup><a href=\"#references\"><b>9</b></a></sup>, showcasing its capability to effectively handle real-world, complex text classification tasks without extensive manual data labeling.\n","\n","### 1.2.3 Contribution to Research\n","KeyClass significantly contributes to the field by addressing the high costs and labor-intensive processes involved in manual ICD code assignment. It provides a scalable and efficient solution that could be adopted widely in healthcare settings to enhance the accuracy and efficiency of medical coding practices. The model's ability to perform well without labeled data presents a significant advancement in machine learning applications within the healthcare sector, offering a pathway toward more automated and accessible medical record management systems. This approach not only aligns with the ongoing needs for improved data handling in healthcare but also sets a foundation for future research in automated systems that require minimal human intervention while maintaining high accuracy and reliability."]},{"cell_type":"markdown","metadata":{"id":"PiLd2ozfFqcE"},"source":["<a id='methodology'></a>\n","## 2. Methodology"]},{"cell_type":"markdown","source":["Instead of relying on previously labeled documents, KeyClass combines the linguistic domain expertise of pre-trained models and easily obtained class descriptions to label data.\n","\n","In the following notebook, we've built on the tutorial provided by the authors of the paper to create an easy way to familiarize yourself with the KeyClass framework using the same IMDb Dataset."],"metadata":{"id":"cCBK1athCwGE"}},{"cell_type":"markdown","metadata":{"id":"FfL89dr3FqcE"},"source":["<a id='classdesc'></a>\n","### 2.1 Find Class Descriptions\n","\n","The IMDb dataset is often used for movie review sentiments. A movie review can be classified as either being `positive` or `negative`.\n","\n","In order to being classification, we provide general descriptions of the two classes. A class description for *positive* can be `good, amazing, exciting, positive, fun`. Similarly, a class description for a *negative* `terrible, bad, boring, negative`.\n","\n","These descriptions can either be generated by mining sources as such as Wikipedia or through more official categorizations, such as the ICD9's long category descriptions.\n","\n","Class Descriptions used in this tutorial can be found [here](./config_files/config_imdb.yml)"]},{"cell_type":"markdown","metadata":{"id":"NkJzCGPLFqcE"},"source":["<a id='keywords'></a>\n","### 2.2 Find Relevant Keywords / Encoding the Dataset\n","\n","KeyClass uses these class descriptions to find 1 to 3 word keywords and phrases that are highly suggestive of each class.\n","Using pre-trained models such as the `paraphrase-mpnet-v2` or more specialized linguistic models, such as BlueBert, it creates labeling functions to map each keyword or phrase to the class description it's most closely related to. A subsampling of top-k labeling functions per class is used in order to account for computation and space constraints."]},{"cell_type":"markdown","source":["##  2.3 Setting Up the Environment"],"metadata":{"id":"OK7ColeoEgP-"}},{"cell_type":"markdown","source":["Please uncomment the following cells and run the commands to begin setting up your environment."],"metadata":{"id":"OuwSKf6gE7ml"}},{"cell_type":"code","source":["!pip install pyyaml"],"metadata":{"id":"6DjXlqsDGlZW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715115382821,"user_tz":300,"elapsed":7780,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}},"outputId":"1765abc8-7f04-4ca5-97c9-2c84997c6269"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n"]}]},{"cell_type":"code","source":["!pip install sentence-transformers"],"metadata":{"id":"MU764-1iG5rk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715115456114,"user_tz":300,"elapsed":73322,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}},"outputId":"db291e85-9d88-4620-efa0-504cdb23d5d8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentence-transformers\n","  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.40.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.7.0\n"]}]},{"cell_type":"code","source":["!pip install snorkel transformers sentence-transformers cleantext pyhealth gdown"],"metadata":{"id":"qge5zJtAG9GP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715115478384,"user_tz":300,"elapsed":22346,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}},"outputId":"d086b43a-eebc-48dc-a77f-0338cd4fa41d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting snorkel\n","  Downloading snorkel-0.9.9-py3-none-any.whl (103 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m178.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.7.0)\n","Collecting cleantext\n","  Downloading cleantext-1.1.4-py3-none-any.whl (4.9 kB)\n","Collecting pyhealth\n","  Downloading pyhealth-1.1.6-py2.py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n","Collecting munkres>=1.0.6 (from snorkel)\n","  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from snorkel) (1.25.2)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from snorkel) (1.11.4)\n","Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from snorkel) (2.0.3)\n","Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from snorkel) (4.66.4)\n","Requirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from snorkel) (1.2.2)\n","Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from snorkel) (2.2.1+cu121)\n","Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from snorkel) (2.15.2)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from snorkel) (3.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from cleantext) (3.8.1)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from pyhealth) (0.17.1+cu121)\n","Collecting rdkit>=2022.03.4 (from pyhealth)\n","  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pandas>=1.0.0 (from snorkel)\n","  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pandarallel>=1.5.3 (from pyhealth)\n","  Downloading pandarallel-1.6.5.tar.gz (14 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting mne>=1.0.3 (from pyhealth)\n","  Downloading mne-1.7.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting urllib3<=1.26.15 (from pyhealth)\n","  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne>=1.0.3->pyhealth) (4.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne>=1.0.3->pyhealth) (3.1.3)\n","Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne>=1.0.3->pyhealth) (0.4)\n","Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne>=1.0.3->pyhealth) (3.7.1)\n","Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne>=1.0.3->pyhealth) (1.8.1)\n","Collecting dill>=0.3.1 (from pandarallel>=1.5.3->pyhealth)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from pandarallel>=1.5.3->pyhealth) (5.9.5)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->snorkel) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->snorkel) (2023.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.2->snorkel) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.2->snorkel) (3.5.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (1.63.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (3.6)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (1.12)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.2.0->snorkel) (12.4.127)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (8.1.7)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.7.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->snorkel) (1.3.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.0.3->pyhealth) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.0.3->pyhealth) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.0.3->pyhealth) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.0.3->pyhealth) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.0.3->pyhealth) (3.1.2)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne>=1.0.3->pyhealth) (4.2.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->snorkel) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.2.0->snorkel) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->snorkel) (3.2.2)\n","Building wheels for collected packages: pandarallel\n","  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pandarallel: filename=pandarallel-1.6.5-py3-none-any.whl size=16673 sha256=dc8168159485fd9a2ed6f22936bb1230a83803c91bc2436bb1defa93c672fb74\n","  Stored in directory: /root/.cache/pip/wheels/50/4f/1e/34e057bb868842209f1623f195b74fd7eda229308a7352d47f\n","Successfully built pandarallel\n","Installing collected packages: munkres, urllib3, rdkit, dill, pandas, cleantext, pandarallel, mne, pyhealth, snorkel\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.0.7\n","    Uninstalling urllib3-2.0.7:\n","      Successfully uninstalled urllib3-2.0.7\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.0.3\n","    Uninstalling pandas-2.0.3:\n","      Successfully uninstalled pandas-2.0.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cleantext-1.1.4 dill-0.3.8 mne-1.7.0 munkres-1.1.4 pandarallel-1.6.5 pandas-1.5.3 pyhealth-1.1.6 rdkit-2023.9.6 snorkel-0.9.9 urllib3-1.26.15\n"]}]},{"cell_type":"markdown","source":["## 2.4 Mounting Google Drive"],"metadata":{"id":"8h8zgeudFYiK"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Wi0EqVkHCBB","executionInfo":{"status":"ok","timestamp":1715119240996,"user_tz":300,"elapsed":1811,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}},"outputId":"6c27b804-24a9-4f97-9602-116157c852d7"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["import sys\n","base_path = '/content/drive/MyDrive/KeyClass/'\n","sys.path.append(base_path + 'keyclass/')\n","sys.path.append(base_path + 'scripts/')"],"metadata":{"id":"4gg6y4OqHDmP","executionInfo":{"status":"ok","timestamp":1715119240996,"user_tz":300,"elapsed":6,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"FZLDEDnMFqcE","executionInfo":{"status":"ok","timestamp":1715119240997,"user_tz":300,"elapsed":6,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}}},"outputs":[],"source":["import argparse\n","import pandas, plotly, matplotlib, seaborn\n","import label_data, encode_datasets, train_downstream_model\n","import torch\n","import pickle\n","import numpy as np\n","import os\n","from os.path import join, exists\n","from datetime import datetime\n","import utils\n","import models\n","import create_lfs\n","import train_classifier"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"FrSezWGmFqcE","executionInfo":{"status":"ok","timestamp":1715119244412,"user_tz":300,"elapsed":116,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}}},"outputs":[],"source":["# Input arguments\n","config_file_path = base_path+'/config_files/config_imdb.yml' # Specify path to the configuration file\n","random_seed = 0 # Random seed for experiments"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"utYTqbtwFqcE","outputId":"068ab3e5-3d8a-4aa8-d4e5-09b2b26a7206","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715105587592,"user_tz":300,"elapsed":1937,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["args = utils.Parser(config_file_path=config_file_path).parse()\n","\n","if args['use_custom_encoder']:\n","    model = models.CustomEncoder(pretrained_model_name_or_path=args['base_encoder'],\n","        device='cuda' if torch.cuda.is_available() else 'cpu')\n","else:\n","    model = models.Encoder(model_name=args['base_encoder'],\n","        device='cuda' if torch.cuda.is_available() else 'cpu')\n","\n","for split in ['train', 'test']:\n","    sentences = utils.fetch_data(dataset=args['dataset'], split=split, path=args['data_path'])\n","    embeddings = model.encode(sentences=sentences, batch_size=args['end_model_batch_size'],\n","                                show_progress_bar=args['show_progress_bar'],\n","                                normalize_embeddings=args['normalize_embeddings'])\n","    with open(join(args['data_path'], args['dataset'], f'{split}_embeddings.pkl'), 'wb') as f:\n","        pickle.dump(embeddings, f)"]},{"cell_type":"markdown","metadata":{"id":"_ALvO8ECFqcF"},"source":["<a id='label'></a>\n","### 2.5 Probabilistically Labeling the Data\n","\n","*KeyClass* creates a matrix that represents how different labeling functions agree or disagree on labeling the training documents. Then, it uses the open-source label model implementation from the Snorkel Python library to turn these agreements and disagreements into probabilistic labels-- it assigns labels with a measure of uncertainty or confidence rather than just labeling them directly.\n","\n","This approach helps in handling complex or noisy data where simple labeling might be difficult or unreliable.\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"pRn1IIhKFqcF","outputId":"5bcaa458-4e6b-4526-8517-5e542283df80","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715105625320,"user_tz":300,"elapsed":30579,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Getting labels for the imdb data...\n","Size of the data: 25000\n","Class distribution (array([0, 1]), array([12500, 12500]))\n","Found assigned category counts [6789 9578]\n","labeler.vocabulary:\n"," 16367\n","labeler.word_indicator_matrix.shape (25000, 600)\n","Len keywords 600\n","assigned_category: Unique and Counts (array([0, 1]), array([300, 300]))\n","negative, hate, expensive, bad, poor, broke, waste, horrible, would not recommend ['abominable' 'abomination' 'absolute worst' 'absolutely awful'\n"," 'absolutely terrible' 'abuse' 'abused' 'abusive' 'abysmal'\n"," 'acting horrible' 'acting poor' 'acting terrible' 'actors bad'\n"," 'actually bad' 'also bad' 'among worst' 'annoyance' 'annoying' 'appalled'\n"," 'appalling' 'atrocious' 'awful' 'awfully' 'awfulness' 'bad' 'bad actor'\n"," 'bad actors' 'bad actually' 'bad almost' 'bad bad' 'bad could'\n"," 'bad either' 'bad enough' 'bad even' 'bad film' 'bad films' 'bad get'\n"," 'bad horror' 'bad idea' 'bad like' 'bad made' 'bad makes' 'bad many'\n"," 'bad movie' 'bad movies' 'bad music' 'bad one' 'bad ones' 'bad people'\n"," 'bad really' 'bad reviews' 'bad special' 'bad story' 'bad taste'\n"," 'bad thing' 'bad things' 'bad think' 'bad way' 'bad well' 'bad would'\n"," 'baddies' 'badly' 'badly made' 'badness' 'best worst' 'better worse'\n"," 'big disappointment' 'chose' 'complain' 'complained' 'complaining'\n"," 'complains' 'crap like' 'crappy' 'criticism' 'criticisms' 'criticize'\n"," 'criticized' 'cursed' 'cursing' 'cynical' 'cynicism' 'depressed'\n"," 'depressing' 'despair' 'desperation' 'despicable' 'despise'\n"," 'disappointed' 'disappointing' 'disappointment' 'disastrous' 'disdain'\n"," 'disgust' 'disgusted' 'disgusting' 'dislike' 'disliked' 'dismal'\n"," 'displeasure' 'distasteful' 'distraught' 'dreaded' 'dreadful'\n"," 'dreadfully' 'easily worst' 'else say' 'even bad' 'even worst'\n"," 'far worse' 'far worst' 'feel bad' 'feel sorry' 'film awful' 'film bad'\n"," 'film terrible' 'film worst' 'films bad' 'filth' 'filthy' 'get bad'\n"," 'god awful' 'greed' 'hapless' 'hate' 'hate film' 'hate movie' 'hated'\n"," 'hated movie' 'hateful' 'hates' 'hating' 'hatred' 'hideous' 'hideously'\n"," 'honestly say' 'horrendous' 'horrible' 'horrible film' 'horrible movie'\n"," 'horribly' 'horrid' 'horrific' 'huge disappointment' 'humble opinion'\n"," 'idiotic' 'immoral' 'incredibly bad' 'incredibly stupid' 'irresponsible'\n"," 'know bad' 'lack' 'lackluster' 'laughably bad' 'least good' 'like bad'\n"," 'like cheap' 'like horror' 'like least' 'like say' 'loathing' 'lot bad'\n"," 'lousy' 'love bad' 'love hate' 'low quality' 'made bad'\n"," 'major disappointment' 'make bad' 'many bad' 'mean spirited' 'mediocrity'\n"," 'miserable' 'miserably' 'misery' 'misfortune' 'misguided' 'movie awful'\n"," 'movie bad' 'movie horrible' 'movie terrible' 'movie worst' 'movies bad'\n"," 'much worse' 'nasty' 'needless say' 'needlessly' 'negative comments'\n"," 'negative reviews' 'never want' 'nothing good' 'notorious' 'one awful'\n"," 'one bad' 'one worst' 'opinion' 'opinions' 'pathetic' 'people hate'\n"," 'pity' 'plain awful' 'plain bad' 'plain stupid' 'poor' 'poor quality'\n"," 'poorest' 'poorly' 'possibly worst' 'poverty' 'pretty awful' 'pretty bad'\n"," 'pretty lame' 'pretty poor' 'probably worst' 'quite bad' 'rather poor'\n"," 'really annoying' 'really awful' 'really bad' 'really disappointed'\n"," 'really hate' 'really poor' 'really sad' 'really stupid'\n"," 'really terrible' 'refuse' 'regret' 'regrets' 'reject' 'repulsive'\n"," 'rotten' 'sad' 'sad thing' 'saddest' 'sadistic' 'sadly' 'sadness'\n"," 'say bad' 'say worst' 'see bad' 'seedy' 'simply awful' 'something bad'\n"," 'still bad' 'story bad' 'stupid' 'stupidest' 'stupidity' 'stupidly'\n"," 'sucks' 'terrible' 'terrible film' 'terrible movie' 'terribly'\n"," 'think bad' 'tiresome' 'trash' 'trashy' 'truly awful' 'truly bad' 'ugly'\n"," 'unappealing' 'unattractive' 'unbearably' 'uneducated' 'unfortunate'\n"," 'unfortunately' 'unfortunately film' 'unhappy' 'unimaginative'\n"," 'unimpressive' 'uninteresting' 'unlikable' 'unlikeable' 'unlucky'\n"," 'unnecessarily' 'unpleasant' 'unrealistic' 'unremarkable' 'unsatisfied'\n"," 'unsatisfying' 'unsympathetic' 'unwilling' 'waste money' 'worse'\n"," 'worse movie' 'worse movies' 'worst' 'worst acting' 'worst ever'\n"," 'worst film' 'worst films' 'worst kind' 'worst movie' 'worst movies'\n"," 'worst part' 'worst thing' 'worthless' 'wretched' 'writing bad']\n","good, positive, excellent, amazing, love, fine, good quality, would recommend ['actually good' 'actually like' 'admirable' 'admirably' 'admired'\n"," 'almost good' 'also enjoyed' 'also excellent' 'also good' 'also great'\n"," 'also interesting' 'also like' 'also liked' 'also nice' 'also pretty'\n"," 'also well' 'always good' 'always great' 'among best' 'another good'\n"," 'another great' 'another reviewer' 'anyone likes' 'anything good'\n"," 'award best' 'bad good' 'best' 'best best' 'best ever' 'best one'\n"," 'best parts' 'best performance' 'best show' 'best thing' 'best things'\n"," 'better ones' 'certainly good' 'commendable' 'damn good'\n"," 'definitely good' 'definitely recommend' 'definitely worth' 'done good'\n"," 'done great' 'enjoy' 'enjoy good' 'enjoyable' 'enjoyable film'\n"," 'enjoyable movie' 'enjoyable watch' 'enough good' 'entertainment value'\n"," 'especially good' 'especially like' 'especially liked' 'even good'\n"," 'even great' 'excellence' 'excellent' 'excellent film' 'excellent job'\n"," 'excellent movie' 'excellent performance' 'excellent performances'\n"," 'excellently' 'exquisite' 'extremely well' 'fabulous' 'fairly good'\n"," 'fantastic' 'far best' 'film excellent' 'find good' 'fine job'\n"," 'fine performances' 'finest' 'first rate' 'get good' 'give good'\n"," 'gives best' 'gives good' 'gives great' 'good' 'good action' 'good also'\n"," 'good although' 'good bad' 'good choice' 'good direction' 'good either'\n"," 'good enough' 'good entertainment' 'good especially' 'good even'\n"," 'good example' 'good film' 'good films' 'good first' 'good good'\n"," 'good great' 'good idea' 'good movie' 'good music' 'good one' 'good ones'\n"," 'good original' 'good part' 'good parts' 'good people' 'good performance'\n"," 'good performances' 'good really' 'good reviews' 'good say' 'good show'\n"," 'good special' 'good stuff' 'good taste' 'good thing' 'good things'\n"," 'good think' 'good though' 'good tv' 'good use' 'good well' 'good work'\n"," 'good would' 'good writing' 'got good' 'got great' 'great'\n"," 'great character' 'great example' 'great film' 'great fun' 'great love'\n"," 'great music' 'great one' 'great really' 'great show' 'great supporting'\n"," 'great things' 'great time' 'greats' 'high quality' 'high rating'\n"," 'highly recommend' 'highly recommended' 'however like' 'idea good'\n"," 'like best' 'like good' 'like great' 'liked' 'liked one' 'looks great'\n"," 'lot good' 'lot great' 'love good' 'lovely' 'luxury' 'made good'\n"," 'made great' 'made well' 'make good' 'make great' 'makes good'\n"," 'makes great' 'many good' 'many great' 'many reviewers' 'many reviews'\n"," 'marvelously' 'may good' 'mean good' 'might good' 'movie excellent'\n"," 'movie good' 'movie recommend' 'movie wonderful' 'much enjoyed'\n"," 'much good' 'music good' 'music great' 'nearly good' 'nice' 'nice look'\n"," 'nothing better' 'one best' 'one finest' 'one good' 'one great'\n"," 'one like' 'overall good' 'overall think' 'particularly good'\n"," 'people good' 'people like' 'performances good' 'perhaps best'\n"," 'personal favorite' 'personally think' 'pleasant' 'positive reviews'\n"," 'positive thing' 'possibly best' 'praise' 'prefer' 'prefers'\n"," 'pretty decent' 'pretty good' 'probably best' 'probably good'\n"," 'probably like' 'put good' 'qualities' 'quality' 'quality acting'\n"," 'quite enjoyable' 'quite good' 'quite like' 'rather good' 'rating 10'\n"," 'read review' 'read reviews' 'reading reviews' 'real good'\n"," 'really appreciate' 'really enjoy' 'really enjoyed' 'really good'\n"," 'really great' 'really like' 'really liked' 'really loved' 'really nice'\n"," 'really recommend' 'recommend' 'recommend anyone' 'recommend everyone'\n"," 'recommend film' 'recommend movie' 'recommend one' 'recommend see'\n"," 'recommend watch' 'recommend watching' 'recommendation' 'recommended'\n"," 'recommending' 'redeeming quality' 'reviews' 'satisfactory' 'say best'\n"," 'say good' 'see good' 'seen good' 'show good' 'solid performances'\n"," 'something better' 'something good' 'something interesting' 'splendid'\n"," 'still enjoyable' 'still good' 'still great' 'strongly recommend'\n"," 'surprisingly good' 'tasteful' 'terrific' 'thing good' 'think best'\n"," 'think good' 'think great' 'though good' 'thought good' 'thought great'\n"," 'time great' 'top notch' 'truly great' 'two best' 'want good'\n"," 'watch good' 'well crafted' 'well good' 'well great' 'well made'\n"," 'well produced' 'well worth' 'wonderful' 'wonderful film' 'wonderful job'\n"," 'wonderful life' 'wonderful movie' 'wonderfully' 'worth look'\n"," 'worth mentioning' 'worth seeing' 'worthwhile' 'would good'\n"," 'would recommend']\n","==== Training the label model ====\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:03<00:00, 33.23epoch/s]\n"]},{"output_type":"stream","name":"stdout","text":["Label Model Predictions: Unique value and counts (array([0, 1]), array([ 8914, 16086]))\n","Label Model Training Accuracy 0.70016\n","Saving results in /content/drive/MyDrive/KeyClass/results/imdb/train_label_model_with_ground_truth_07-May-2024-18_13_45.txt...\n"]}],"source":["# Load training data\n","train_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='train')\n","\n","training_labels_present = False\n","if exists(join(args['data_path'], args['dataset'], 'train_labels.txt')):\n","    with open(join(args['data_path'], args['dataset'], 'train_labels.txt'), 'r') as f:\n","        y_train = f.readlines()\n","    y_train = np.array([int(i.replace('\\n','')) for i in y_train])\n","    training_labels_present = True\n","else:\n","    y_train = None\n","    training_labels_present = False\n","    print('No training labels found!')\n","\n","with open(join(args['data_path'], args['dataset'], 'train_embeddings.pkl'), 'rb') as f:\n","    X_train = pickle.load(f)\n","\n","# Print dataset statistics\n","print(f\"Getting labels for the {args['dataset']} data...\")\n","print(f'Size of the data: {len(train_text)}')\n","if training_labels_present:\n","    print('Class distribution', np.unique(y_train, return_counts=True))\n","\n","# Load label names/descriptions\n","label_names = []\n","for a in args:\n","    if 'target' in a: label_names.append(args[a])\n","\n","# Creating labeling functions\n","labeler = create_lfs.CreateLabellingFunctions(base_encoder=args['base_encoder'],\n","                                            device=torch.device(args['device']),\n","                                            label_model=args['label_model'])\n","proba_preds = labeler.get_labels(text_corpus=train_text, label_names=label_names, min_df=args['min_df'],\n","                                ngram_range=args['ngram_range'], topk=args['topk'], y_train=y_train,\n","                                label_model_lr=args['label_model_lr'], label_model_n_epochs=args['label_model_n_epochs'],\n","                                verbose=True, n_classes=args['n_classes'])\n","\n","y_train_pred = np.argmax(proba_preds, axis=1)\n","\n","# Save the predictions\n","if not os.path.exists(args['preds_path']): os.makedirs(args['preds_path'])\n","with open(join(args['preds_path'], f\"{args['label_model']}_proba_preds.pkl\"), 'wb') as f:\n","    pickle.dump(proba_preds, f)\n","\n","# Print statistics\n","print('Label Model Predictions: Unique value and counts', np.unique(y_train_pred, return_counts=True))\n","if training_labels_present:\n","    print('Label Model Training Accuracy', np.mean(y_train_pred==y_train))\n","\n","    # Log the metrics\n","    training_metrics_with_gt = utils.compute_metrics(y_preds=y_train_pred, y_true=y_train, average=args['average'])\n","    utils.log(metrics=training_metrics_with_gt, filename='label_model_with_ground_truth',\n","        results_dir=args['results_path'], split='train')"]},{"cell_type":"markdown","metadata":{"id":"QgX7ctGLFqcF"},"source":["<a id='exp_training'></a>\n","## 3. Experimentation: Training"]},{"cell_type":"markdown","metadata":{"id":"V0Ty0uhFFqcF"},"source":["<a id='downstream'></a>\n","### 3.1 Training the Downstream Model\n","\n","Now, we have a proabilitistically labeled training dataset that can be used to train our downstream classfier. KeyClass uses the top-*k* documents with the most confident label estimates to train the classifier. This model will be saved under './models/{dataset_name}' as end_model and the date."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"TB2MM7dMFqcF","outputId":"995758bb-323c-411c-ec91-9629b8d58184","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715105660154,"user_tz":300,"elapsed":34861,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Confidence of least confident data point of class 0: 0.9118952135029044\n","Confidence of least confident data point of class 1: 0.9999157389438634\n","\n","==== Data statistics ====\n","Size of training data: (25000, 768), testing data: (25000, 768)\n","Size of testing labels: (25000,)\n","Size of training labels: (25000,)\n","Training class distribution (ground truth): [0.5 0.5]\n","Training class distribution (label model predictions): [0.35656 0.64344]\n","\n","KeyClass only trains on the most confidently labeled data points! Applying mask...\n","\n","==== Data statistics (after applying mask) ====\n","Size of training data: (7000, 768)\n","Size of training labels: (7000,)\n","Training class distribution (ground truth): [0.55057143 0.44942857]\n","Training class distribution (label model predictions): [0.5 0.5]\n","\n","===== Training the downstream classifier =====\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16:  80%|████████  | 16/20 [00:03<00:00,  4.54batch/s, best_loss=0.543, running_loss=0.549, tolerance_count=2]\n"]},{"output_type":"stream","name":"stdout","text":["Stopping early...\n","Saving model end_model_07-May-2024.pth...\n","Saving results in /content/drive/MyDrive/KeyClass/results/imdb/train_end_model_with_ground_truth_07-May-2024-18_14_16.txt...\n","Saving results in /content/drive/MyDrive/KeyClass/results/imdb/train_end_model_with_label_model_07-May-2024-18_14_16.txt...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n","[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n","[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    2.5s\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/MyDrive/KeyClass/results/imdb/test_end_model_with_ground_truth_07-May-2024-18_14_19.txt...\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    3.0s finished\n"]}],"source":["args = utils.Parser(config_file_path=config_file_path).parse()\n","\n","# Set random seeds\n","random_seed = random_seed\n","torch.manual_seed(random_seed)\n","np.random.seed(random_seed)\n","\n","X_train_embed_masked, y_train_lm_masked, y_train_masked, \\\n","\tX_test_embed, y_test, training_labels_present, \\\n","\tsample_weights_masked, proba_preds_masked = train_downstream_model.load_data(args)\n","\n","# Train a downstream classifier\n","\n","if args['use_custom_encoder']:\n","\tencoder = models.CustomEncoder(pretrained_model_name_or_path=args['base_encoder'], device=args['device'])\n","else:\n","\tencoder = models.Encoder(model_name=args['base_encoder'], device=args['device'])\n","\n","classifier = models.FeedForwardFlexible(encoder_model=encoder,\n","\t\t\t\t\t\t\t\t\t\th_sizes=args['h_sizes'],\n","\t\t\t\t\t\t\t\t\t\tactivation=eval(args['activation']),\n","\t\t\t\t\t\t\t\t\t\tdevice=torch.device(args['device']))\n","print('\\n===== Training the downstream classifier =====\\n')\n","model = train_classifier.train(model=classifier,\n","\t\t\t\t\t\t\tdevice=torch.device(args['device']),\n","\t\t\t\t\t\t\tX_train=X_train_embed_masked,\n","\t\t\t\t\t\t\ty_train=y_train_lm_masked,\n","\t\t\t\t\t\t\tsample_weights=sample_weights_masked if args['use_noise_aware_loss'] else None,\n","\t\t\t\t\t\t\tepochs=args['end_model_epochs'],\n","\t\t\t\t\t\t\tbatch_size=args['end_model_batch_size'],\n","\t\t\t\t\t\t\tcriterion=eval(args['criterion']),\n","\t\t\t\t\t\t\traw_text=False,\n","\t\t\t\t\t\t\tlr=eval(args['end_model_lr']),\n","\t\t\t\t\t\t\tweight_decay=eval(args['end_model_weight_decay']),\n","\t\t\t\t\t\t\tpatience=args['end_model_patience'])\n","\n","# # Saving the model\n","# if not os.path.exists(args['preds_path']): os.makedirs(args['preds_path'])\n","# with open(join(args['preds_path'], f\"{args['label_model']}_proba_preds.pkl\"), 'wb') as f:\n","#     pickle.dump(proba_preds, f)\n","\n","\n","# end_model_preds_train = model.predict_proba(torch.from_numpy(X_train_embed_masked), batch_size=512, raw_text=False)\n","# end_model_preds_test = model.predict_proba(torch.from_numpy(X_test_embed), batch_size=512, raw_text=False)\n","\n","\n","if not os.path.exists(args['model_path']): os.makedirs(args['model_path'])\n","current_time = datetime.now()\n","model_name = f'end_model_{current_time.strftime(\"%d-%b-%Y\")}.pth'\n","print(f'Saving model {model_name}...')\n","with open(join(args['model_path'], model_name), 'wb') as f:\n","\t\ttorch.save(model, f)\n","\n","end_model_preds_train = model.predict_proba(\n","\t\t \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t torch.from_numpy(X_train_embed_masked),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t batch_size=512, raw_text=False)\n","end_model_preds_test = model.predict_proba(torch.from_numpy(X_test_embed),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=512,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\traw_text=False)\n","\n","# Save the predictions\n","with open(join(args['preds_path'], 'end_model_preds_train.pkl'),\n","\t\t\t\t\t'wb') as f:\n","\t\tpickle.dump(end_model_preds_train, f)\n","with open(join(args['preds_path'], 'end_model_preds_test.pkl'), 'wb') as f:\n","\t\tpickle.dump(end_model_preds_test, f)\n","\n","# Print statistics\n","if training_labels_present:\n","\t\ttraining_metrics_with_gt = utils.compute_metrics(\n","\t\t\t\ty_preds=np.argmax(end_model_preds_train, axis=1),\n","\t\t\t\ty_true=y_train_masked,\n","\t\t\t\taverage=args['average'])\n","\t\tutils.log(metrics=training_metrics_with_gt,\n","\t\t\t\t\t\t\tfilename='end_model_with_ground_truth',\n","\t\t\t\t\t\t\tresults_dir=args['results_path'],\n","\t\t\t\t\t\t\tsplit='train')\n","\n","training_metrics_with_lm = utils.compute_metrics(y_preds=np.argmax(\n","\t\tend_model_preds_train, axis=1),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ty_true=y_train_lm_masked,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\taverage=args['average'])\n","utils.log(metrics=training_metrics_with_lm,\n","\t\t\t\t\tfilename='end_model_with_label_model',\n","\t\t\t\t\tresults_dir=args['results_path'],\n","\t\t\t\t\tsplit='train')\n","\n","testing_metrics = utils.compute_metrics_bootstrap(\n","\t\ty_preds=np.argmax(end_model_preds_test, axis=1),\n","\t\ty_true=y_test,\n","\t\taverage=args['average'],\n","\t\tn_bootstrap=args['n_bootstrap'],\n","\t\tn_jobs=args['n_jobs'])\n","utils.log(metrics=testing_metrics,\n","\t\t\t\t\tfilename='end_model_with_ground_truth',\n","\t\t\t\t\tresults_dir=args['results_path'],\n","\t\t\t\t\tsplit='test')"]},{"cell_type":"markdown","metadata":{"id":"wav234FmFqcF"},"source":["<a id='self'></a>\n","### 3.2 Self-Training the Model\n","Lastly, KeyClass self-trains on the entire training dataset to refine the end model classifier further. It saves this model to the same location as end_model_with_self_training and the date."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nG-Qr6X5FqcF","outputId":"61404cc3-311c-482b-ce82-d506bc2179e6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715109083178,"user_tz":300,"elapsed":3423052,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 8:  13%|█▎        | 8/62 [42:02<4:43:49, 315.35s/batch, self_train_agreement=1, tolerance_count=2, validation_accuracy=0.915]\n","[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n","[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    2.4s\n","[Parallel(n_jobs=10)]: Done  81 out of 100 | elapsed:    2.5s remaining:    0.6s\n","[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    2.8s finished\n"]},{"output_type":"stream","name":"stdout","text":["Saving model end_model_self_trained_07 May 2024.pth...\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n","[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    2.4s\n","[Parallel(n_jobs=10)]: Done  81 out of 100 | elapsed:    2.5s remaining:    0.6s\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/MyDrive/KeyClass/results/imdb/test_end_model_with_ground_truth_self_trained_07-May-2024-19_11_23.txt...\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    2.9s finished\n"]}],"source":["# Fetching the raw text data for self-training\n","X_train_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='train')\n","X_test_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='test')\n","\n","model = train_classifier.self_train(model=model,\n","\t\t\t\t\t\t\t\t\tX_train=X_train_text,\n","\t\t\t\t\t\t\t\t\tX_val=X_test_text,\n","\t\t\t\t\t\t\t\t\ty_val=y_test,\n","\t\t\t\t\t\t\t\t\tdevice=torch.device(args['device']),\n","\t\t\t\t\t\t\t\t\tlr=eval(args['self_train_lr']),\n","\t\t\t\t\t\t\t\t\tweight_decay=eval(args['self_train_weight_decay']),\n","\t\t\t\t\t\t\t\t\tpatience=args['self_train_patience'],\n","\t\t\t\t\t\t\t\t\tbatch_size=args['self_train_batch_size'],\n","\t\t\t\t\t\t\t\t\tq_update_interval=args['q_update_interval'],\n","\t\t\t\t\t\t\t\t\tself_train_thresh=eval(args['self_train_thresh']),\n","\t\t\t\t\t\t\t\t\tprint_eval=True)\n","\n","\n","end_model_preds_test = model.predict_proba(X_test_text, batch_size=args['self_train_batch_size'], raw_text=True)\n","\n","\n","# Print statistics\n","testing_metrics = utils.compute_metrics_bootstrap(y_preds=np.argmax(end_model_preds_test, axis=1),\n","\t\t\t\t\t\t\t\t\t\t\t\t\ty_true=y_test,\n","\t\t\t\t\t\t\t\t\t\t\t\t\taverage=args['average'],\n","\t\t\t\t\t\t\t\t\t\t\t\t\tn_bootstrap=args['n_bootstrap'],\n","\t\t\t\t\t\t\t\t\t\t\t\t\tn_jobs=args['n_jobs'])\n","\n","\n","current_time = datetime.now()\n","model_name = f'end_model_self_trained_{current_time.strftime(\"%d %b %Y\")}.pth'\n","print(f'Saving model {model_name}...')\n","with open(join(args['model_path'], model_name), 'wb') as f:\n","\t\ttorch.save(model, f)\n","\n","end_model_preds_test = model.predict_proba(\n","\t\tX_test_text, batch_size=args['self_train_batch_size'], raw_text=True)\n","\n","# Save the predictions\n","with open(\n","\t\t\t\tjoin(args['preds_path'], 'end_model_self_trained_preds_test.pkl'),\n","\t\t\t\t'wb') as f:\n","\t\tpickle.dump(end_model_preds_test, f)\n","\n","# Print statistics\n","testing_metrics = utils.compute_metrics_bootstrap(\n","\t\ty_preds=np.argmax(end_model_preds_test, axis=1),\n","\t\ty_true=y_test,\n","\t\taverage=args['average'],\n","\t\tn_bootstrap=args['n_bootstrap'],\n","\t\tn_jobs=args['n_jobs'])\n","utils.log(metrics=testing_metrics,\n","\t\t\t\t\tfilename='end_model_with_ground_truth_self_trained',\n","\t\t\t\t\tresults_dir=args['results_path'],\n","\t\t\t\t\tsplit='test')"]},{"cell_type":"markdown","metadata":{"id":"v1Na3Dr6FqcG"},"source":["<a id='exp_testing'></a>\n","## 4. Experimentation: Testing"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"4BIbiI49FqcG","outputId":"fda976b0-2198-45c6-dbdc-95cfc722b16c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715109629892,"user_tz":300,"elapsed":451186,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Confidence of least confident data point of class 0: 0.9118952135029044\n","Confidence of least confident data point of class 1: 0.9999157389438634\n","\n","==== Data statistics ====\n","Size of training data: (25000, 768), testing data: (25000, 768)\n","Size of testing labels: (25000,)\n","Size of training labels: (25000,)\n","Training class distribution (ground truth): [0.5 0.5]\n","Training class distribution (label model predictions): [0.35656 0.64344]\n","\n","KeyClass only trains on the most confidently labeled data points! Applying mask...\n","\n","==== Data statistics (after applying mask) ====\n","Size of training data: (7000, 768)\n","Size of training labels: (7000,)\n","Training class distribution (ground truth): [0.55057143 0.44942857]\n","Training class distribution (label model predictions): [0.5 0.5]\n","training_metrics_with_gt [0.9181428571428571, 0.9226160465912984, 0.9181428571428571]\n","training_metrics_with_lm [0.9218571428571428, 0.9218786672789429, 0.9218571428571428]\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n","[Parallel(n_jobs=10)]: Done  40 tasks      | elapsed:    0.1s\n","[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n"]},{"output_type":"stream","name":"stdout","text":["testing_metrics [[0.8474412  0.0019673 ]\n"," [0.86153452 0.001771  ]\n"," [0.8474412  0.0019673 ]]\n","\n","===== Self-training the downstream classifier =====\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n","/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n","[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    2.5s\n","[Parallel(n_jobs=10)]: Done  81 out of 100 | elapsed:    2.7s remaining:    0.6s\n"]},{"output_type":"stream","name":"stdout","text":["testing_metrics after self train [[0.9151308  0.00171572]\n"," [0.91525774 0.00170526]\n"," [0.9151308  0.00171572]]\n","Saving results in /content/drive/MyDrive/KeyClass/results/imdb/test_end_model_with_ground_truth_self_trained_07-May-2024-19_20_29.txt...\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    2.8s finished\n"]}],"source":["end_model_path='/content/drive/MyDrive/KeyClass/models/imdb/end_model_07-May-2024.pth'\n","end_model_self_trained_path='/content/drive/MyDrive/KeyClass/models/imdb/end_model_self_trained_07 May 2024.pth'\n","\n","args = utils.Parser(config_file_path=config_file_path).parse()\n","\n","# Set random seeds\n","random_seed = random_seed\n","torch.manual_seed(random_seed)\n","np.random.seed(random_seed)\n","\n","X_train_embed_masked, y_train_lm_masked, y_train_masked, \\\n","\tX_test_embed, y_test, training_labels_present, \\\n","\tsample_weights_masked, proba_preds_masked = train_downstream_model.load_data(args)\n","\n","model = torch.load(end_model_path)\n","\n","end_model_preds_train = model.predict_proba(torch.from_numpy(X_train_embed_masked), batch_size=512, raw_text=False)\n","end_model_preds_test = model.predict_proba(torch.from_numpy(X_test_embed), batch_size=512, raw_text=False)\n","\n","# Print statistics\n","if training_labels_present:\n","\ttraining_metrics_with_gt = utils.compute_metrics(y_preds=np.argmax(end_model_preds_train, axis=1),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\ty_true=y_train_masked,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\taverage=args['average'])\n","\tprint('training_metrics_with_gt', training_metrics_with_gt)\n","\n","training_metrics_with_lm = utils.compute_metrics(y_preds=np.argmax(end_model_preds_train, axis=1),\n","\t\t\t\t\t\t\t\t\t\t\t\t\ty_true=y_train_lm_masked,\n","\t\t\t\t\t\t\t\t\t\t\t\t\taverage=args['average'])\n","print('training_metrics_with_lm', training_metrics_with_lm)\n","\n","testing_metrics = utils.compute_metrics_bootstrap(y_preds=np.argmax(end_model_preds_test, axis=1),\n","\t\t\t\t\t\t\t\t\t\t\t\t\ty_true=y_test,\n","\t\t\t\t\t\t\t\t\t\t\t\t\taverage=args['average'],\n","\t\t\t\t\t\t\t\t\t\t\t\t\tn_bootstrap=args['n_bootstrap'],\n","\t\t\t\t\t\t\t\t\t\t\t\t\tn_jobs=args['n_jobs'])\n","print('testing_metrics', testing_metrics)\n","\n","\n","print('\\n===== Self-training the downstream classifier =====\\n')\n","\n","# Fetching the raw text data for self-training\n","X_train_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='train')\n","X_test_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='test')\n","\n","model = torch.load(end_model_self_trained_path)\n","\n","end_model_preds_test = model.predict_proba(X_test_text, batch_size=args['self_train_batch_size'], raw_text=True)\n","\n","\n","# Print statistics\n","testing_metrics = utils.compute_metrics_bootstrap(y_preds=np.argmax(end_model_preds_test, axis=1),\n","\t\t\t\t\t\t\t\t\t\t\t\t\ty_true=y_test,\n","\t\t\t\t\t\t\t\t\t\t\t\t\taverage=args['average'],\n","\t\t\t\t\t\t\t\t\t\t\t\t\tn_bootstrap=args['n_bootstrap'],\n","\t\t\t\t\t\t\t\t\t\t\t\t\tn_jobs=args['n_jobs'])\n","print('testing_metrics after self train', testing_metrics)\n","\n","utils.log(metrics=testing_metrics,\n","\t\t\t\t\tfilename='end_model_with_ground_truth_self_trained',\n","\t\t\t\t\tresults_dir=args['results_path'],\n","\t\t\t\t\tsplit='test')\n"]},{"cell_type":"markdown","source":["## 5. Plotting Results\n","\n","Examine the Accuracy, Prescision, and Recall values of the different models."],"metadata":{"id":"4N7BIGh2H1-B"}},{"cell_type":"code","source":["import json\n","import plotly.graph_objects as go\n","import os\n","args = utils.Parser(config_file_path=config_file_path).parse()\n","\n","test_em_gt = os.path.join(base_path, args['results_path'], 'test_end_model_with_ground_truth_07-May-2024-18_14_19.txt')\n","test_em_gt_st = os.path.join(base_path, args['results_path'], 'test_end_model_with_ground_truth_self_trained_07-May-2024-19_20_29.txt')\n","train_em_gt= os.path.join(base_path, args['results_path'], 'train_end_model_with_ground_truth_07-May-2024-18_14_16.txt')\n","train_em_lm_gt = os.path.join(base_path, args['results_path'], 'train_end_model_with_label_model_07-May-2024-18_14_16.txt')\n","train_lm_gt = os.path.join(base_path, args['results_path'],'train_label_model_with_ground_truth_07-May-2024-18_13_45.txt')\n","\n","\n","\n","\n","\n","files = {\n","    'Train Label Model with Ground Truth': os.path.join(base_path, args['results_path'], 'train_label_model_with_ground_truth_07-May-2024-18_13_45.txt'),\n","    'Train End Model with Label Model': os.path.join(base_path, args['results_path'], 'train_end_model_with_label_model_07-May-2024-18_14_16.txt'),\n","    'Train End Model with Ground Truth': os.path.join(base_path, args['results_path'], 'train_end_model_with_ground_truth_07-May-2024-18_14_16.txt'),\n","    'Test End Model with Ground Truth': os.path.join(base_path, args['results_path'], 'test_end_model_with_ground_truth_07-May-2024-18_14_19.txt'),\n","    'Test Self-Trained End Model with Ground Truth': os.path.join(base_path, args['results_path'], 'test_end_model_with_ground_truth_self_trained_07-May-2024-19_20_29.txt')\n","\n","}\n","\n","# Initialize lists to store the data\n","labels = []\n","accuracy = []\n","precision = []\n","recall = []\n","accuracy_err = []\n","precision_err = []\n","recall_err = []\n","\n","# Read each file and extract the metrics\n","for label, file_path in files.items():\n","    with open(file_path, 'r') as f:\n","        data = json.load(f)\n","        labels.append(label)\n","\n","        if 'mean' in str(data):\n","            # Test models with mean and std\n","            accuracy.append(data['Accuracy (mean, std)'][0])\n","            precision.append(data['Precision (mean, std)'][0])\n","            recall.append(data['Recall (mean, std)'][0])\n","            accuracy_err.append(data['Accuracy (mean, std)'][1])\n","            precision_err.append(data['Precision (mean, std)'][1])\n","            recall_err.append(data['Recall (mean, std)'][1])\n","        else:\n","            # Train models without std\n","            accuracy.append(data['Accuracy'])\n","            precision.append(data['Precision'])\n","            recall.append(data['Recall'])\n","            accuracy_err.append(0)\n","            precision_err.append(0)\n","            recall_err.append(0)\n","\n","# Creating the plot with Plotly\n","fig = go.Figure()\n","\n","# Adding Accuracy, Precision, and Recall traces\n","fig.add_trace(go.Bar(name='Accuracy', x=labels, y=accuracy, error_y=dict(type='data', array=accuracy_err)))\n","fig.add_trace(go.Bar(name='Precision', x=labels, y=precision, error_y=dict(type='data', array=precision_err)))\n","fig.add_trace(go.Bar(name='Recall', x=labels, y=recall, error_y=dict(type='data', array=recall_err)))\n","\n","# Update the layout\n","fig.update_layout(\n","    barmode='group',\n","    title='Performance Metrics Across Different Models',\n","    xaxis_title='IMDb KeyClass Models',\n","    yaxis_title='Metric Value',\n","    legend_title='Metric'\n",")\n","\n","# Show the plot\n","fig.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"4tciHGZdeY7t","executionInfo":{"status":"ok","timestamp":1715120805809,"user_tz":300,"elapsed":127,"user":{"displayName":"Laxmi Vijayan","userId":"15650875999082217427"}},"outputId":"8ed81779-5b68-454f-bf14-053bca829614"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"9d4f309f-8381-4ac7-8665-6cbda424fb09\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9d4f309f-8381-4ac7-8665-6cbda424fb09\")) {                    Plotly.newPlot(                        \"9d4f309f-8381-4ac7-8665-6cbda424fb09\",                        [{\"error_y\":{\"array\":[0,0,0,0.001967296256286787,0.0017157235674781733],\"type\":\"data\"},\"name\":\"Accuracy\",\"x\":[\"Train Label Model with Ground Truth\",\"Train End Model with Label Model\",\"Train End Model with Ground Truth\",\"Test End Model with Ground Truth\",\"Test Self-Trained End Model with Ground Truth\"],\"y\":[0.70016,0.9218571428571428,0.9181428571428571,0.8474412,0.9151308],\"type\":\"bar\"},{\"error_y\":{\"array\":[0,0,0,0.0017710006355608843,0.0017052630026874172],\"type\":\"data\"},\"name\":\"Precision\",\"x\":[\"Train Label Model with Ground Truth\",\"Train End Model with Label Model\",\"Train End Model with Ground Truth\",\"Test End Model with Ground Truth\",\"Test Self-Trained End Model with Ground Truth\"],\"y\":[0.7181105255683281,0.9218786672789429,0.9226160465912984,0.8615345221734962,0.9152577396242796],\"type\":\"bar\"},{\"error_y\":{\"array\":[0,0,0,0.001967296256286787,0.0017157235674781733],\"type\":\"data\"},\"name\":\"Recall\",\"x\":[\"Train Label Model with Ground Truth\",\"Train End Model with Label Model\",\"Train End Model with Ground Truth\",\"Test End Model with Ground Truth\",\"Test Self-Trained End Model with Ground Truth\"],\"y\":[0.70016,0.9218571428571428,0.9181428571428571,0.8474412,0.9151308],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"group\",\"title\":{\"text\":\"Performance Metrics Across Different Models\"},\"xaxis\":{\"title\":{\"text\":\"IMDb KeyClass Models\"}},\"yaxis\":{\"title\":{\"text\":\"Metric Value\"}},\"legend\":{\"title\":{\"text\":\"Metric\"}}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('9d4f309f-8381-4ac7-8665-6cbda424fb09');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"X1cQwwDnFqcG"},"source":["# 5. References\n","\n","[[1](https://pubmed.ncbi.nlm.nih.gov/16178999/)] O’Malley KJ, Cook KF, Price MD, Wildes KR, Hurdle JF, Ashton CM. Measuring diagnoses: ICD code accuracy. Health Serv Res. 2005 Oct;40(5 Pt 2):1620-39. doi: 10.1111/j.1475-6773.2005.00444.x. PMID: 16178999; PMCID: PMC1361216.\n","\n","[[2](https://pubmed.ncbi.nlm.nih.gov/12711737/)] Calle EE, Rodriguez C, Walker-Thurmond K, Thun MJ. \"Overweight, Obesity, and Mortality from Cancer in a Prospectively Studied Cohort of U.S. Adults.\" New England Journal of Medicine. 2003;348(17):1625–38.\n","\n","[[3](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1475-6773.2005.00444.x)] Charbonneau A, Rosen AK, Ash AS, Owen RR, Kader B, Spiro A, Hankin C, Herz LR, Pugh MJV, Kazis L, Miller DR, Berlowitz DR. \"Measuring the Quality of Depression in a Large Integrated Health System.\" Medical Care. 2003;41:669–80.\n","\n","[[4](https://jamanetwork.com/journals/jama/fullarticle/195992)] Studdert DM, Gresenz CR. \"Enrollee Appeals of Preservice Coverage Denials at 2 Health Maintenance Organizations.\" Journal of the American Medical Association. 2003;289(7):864–70.\n","\n","[[5](https://n.neurology.org/content/49/3/660.short)] Curtis Benesch, DM Witter, AL Wilder, PW Duncan, GP Samsa, and DB Matchar. Inaccuracy of the international classification of diseases (icd-9-cm) in identifying the diagnosis of ischemic cerebrovascular disease. Neurology, 49(3):660–664, 1997.\n","\n","[[6](https://doi.org/10.1186/s12911-021-01531-9)] Wabe N, Li L, Lindeman R, et al. Evaluation of the accuracy of diagnostic coding for influenza compared to laboratory results: the availability of test results before hospital discharge facilitates improved coding accuracy. BMC Med Inform Decis Mak 21, 168 (2021).\n","\n","[[7](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-024-02449-8)] Guo LL, Morse KE, Aftandilian C, Steinberg E, Fries J, Posada J, Fleming SL, Lemmon J, Jessa K, Shah N, Sung L. Characterizing the limitations of using diagnosis codes in the context of machine learning for healthcare. BMC Med Inform Decis Mak. 2024 Feb 14;24(1):51. doi: 10.1186/s12911-024-02449-8. PMID: 38355486; PMCID: PMC10868117.\n","\n","[[8](https://pubmed.ncbi.nlm.nih.gov/28595574/)] Burles K, Innes G, Senior K, Lang E, McRae A. Limitations of pulmonary embolism ICD-10 codes in emergency department administrative data: let the buyer beware. BMC Med Res Methodol. 2017;17(1):89. doi: 10.1186/s12874-017-0361-1.\n","\n","[[9](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0234647)] Venkataraman GR, Pineda AL, Bear Don't Walk Iv OJ, Zehnder AM, Ayyar S, Page RL, Bustamante CD, Rivas MA. FasTag: Automatic text classification of unstructured medical narratives. PLoS One. 2020 Jun 22;15(6):e0234647. doi: 10.1371/journal.pone.0234647. PMID: 32569327; PMCID: PMC7307763.\n","\n","[[10](https://ui.adsabs.harvard.edu/abs/2022arXiv220612088G)]Gao C, Goswami M, Chen J, Dubrawski A. Classifying unstructured clinical notes via automatic weak supervision. arXiv. 2022 Jun [cited 2024 Mar 15]. In: arXiv:2206.12088 [cs.CL]. doi: 10.48550/arXiv.2206.12088.\n","\n","[[11](https://doi.org/10.13026/C2XW26.)]Johnson, A., Pollard, T., & Mark, R. (2016). MIMIC-III Clinical Database (version 1.4). PhysioNet. https://doi.org/10.13026/C2XW26.\n","\n","[[12](https://www.nature.com/articles/sdata201635)]Johnson, A. E. W., Pollard, T. J., Shen, L., Lehman, L. H., Feng, M., Ghassemi, M., Moody, B., Szolovits, P., Celi, L. A., & Mark, R. G. (2016). MIMIC-III, a freely accessible critical care database. Scientific Data, 3, 160035.\n","\n","[[13]() Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215–e220.]\n","\n","[[14](https://github.com/drobbins/ICD9/tree/master)]Robbins D. ICD9 [Internet]. GitHub; 2013. [updated 2013 Nov 11; cited 2024 Apr 14]. Available from: https://github.com/drobbins/ICD9/tree/master"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"vscode":{"interpreter":{"hash":"318bfa02e7908bdce70328a8696b89c0eda4a9244e2fc5762a68deeb8a3ec1f0"}},"colab":{"provenance":[{"file_id":"1JuVWcY80akhV8j1sYIpZUCkP6v-hiELs","timestamp":1715052640444}],"machine_shape":"hm","collapsed_sections":["OK7ColeoEgP-"]}},"nbformat":4,"nbformat_minor":0}