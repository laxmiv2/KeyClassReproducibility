{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn0Fv91sO5_s"
      },
      "source": [
        "**Team Number:** 95  \n",
        "**Team Members:** Laxmi Vijayan (laxmiv2), Aganze Mihigo (amihigo)  \n",
        "**GitHub Link:** https://github.com/laxmiv2/KeyClassReproducibility.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0sNuMePBXx"
      },
      "source": [
        "# 1. Introduction\n",
        "\n",
        "## 1.1 Problem Background & Motivation\n",
        "\n",
        "The accuracy of International Classification of Diseases (ICD) codes is paramount in the healthcare sector for several reasons, primarily because these codes are integral to standardized billing practices. This ensures that healthcare providers are reimbursed correctly and efficiently for the services they provide <sup><a href=\"#references\"><b>1</b></a></sup>.\n",
        "Furthermore, ICD codes are crucial in epidemiological studies, where they help in tracking and analyzing the prevalence and incidence of diseases across different populations and geographies. This data is vital for public health officials and policymakers in understanding health trends, allocating resources, and formulating targeted interventions to manage and prevent diseases effectively <sup><a href=\"#references\"><b>2</b></a>,</sup><sup><a href=\"#references\"><b>3</b></a>,</sup><sup><a href=\"#references\"><b>4</b></a></sup>.\n",
        "\n",
        "The assignment of ICD codes is determined through the analysis of Electronic Health Records (EHRs) which are comprehensive, patient-centered records that are digital versions of a patient's paper chart and track a patient’s trajectory through the healthcare system <sup><a href=\"#references\"><b>1</b></a></sup>. These records include detailed medical histories, diagnoses, procedures, and medications, all invaluable for coding purposes. However, the data captured in EHRs can often be unstructured and comprised of medical jargon, making the assignment of ICD codes a labor-intensive process. Consequently, healthcare providers frequently depend on trained coders or third-party vendors. This process is expensive, labor-intensive, and prone to errors due to the subjective interpretation of text and the ever-evolving nature of medical nomenclature and coding systems.\n",
        "\n",
        "Historically, innumerable studies from the 1970s to the present day have examined the accuracy of ICD code assignments, revealing significant variability in error rates —from 20 to 80 percent in the 70s to 3 to 30 percent in 2024 <sup><a href=\"#references\"><b>1</b></a>,</sup><sup><a href=\"#references\"><b>5</b></a>,</sup><sup><a href=\"#references\"><b>6</b></a></sup>. Given the broad impact of ICD codes within the healthcare sector, there is a pressing demand for accuracy and efficiency, which has spurred interest in leveraging machine learning (ML) technologies to automate the coding process. These systems can potentially reduce the time and cost associated with manual coding and improve accuracy by consistently applying the same rules to the available data, thereby minimizing human error.\n",
        "\n",
        "However, conventional ML approaches depend heavily on large volumes of manually labeled data, which are still costly and labor-intensive<sup><a href=\"#references\"><b>9</b></a>,</sup><sup><a href=\"#references\"><b>10</b></a></sup>. This problem is exacerbated twofold by the frequent updates to the ICD, which are not necessarily compatible with previous versions, and by the large variability in the existing labeled diagnostic data as a result of institutional processes or the clinical diagnostic practices of the physicians <sup><a href=\"#references\"><b>1</b></a>,</sup><sup><a href=\"#references\"><b>7</b></a>,</sup><sup><a href=\"#references\"><b>8</b></a></sup>.\n",
        "\n",
        "The need for a reliable, generalizable, cost- and time-effective automated classification system is clear.\n",
        "\n",
        "## 1.2 Classifying Unstructured Clinical Notes via Automatic Weak Supervision\n",
        "\n",
        "In the paper \"Classifying Unstructured Clinical Notes via Automatic Weak Supervision,\" <sup><a href=\"#references\"><b>10</b></a></sup> the authors present a novel framework for text classification, specifically focusing on assigning International Classification of Diseases (ICD) codes to unstructured clinical notes without the need for manually labeled data. This framework, named KeyClass, utilizes a general weakly supervised learning approach, leveraging the linguistic domain knowledge embedded in pre-trained language models and employing a data programming methodology.\n",
        "\n",
        "### 1.2.1 Innovations and Effectiveness\n",
        "\n",
        "KeyClass introduces several innovative approaches:\n",
        "1. **Interpretable Weak Supervision Sources**: It automatically extracts weak supervision sources, such as keywords and phrases from class-label descriptions, allowing the model to learn from these inputs without the need for a human-labeled training set.\n",
        "2. **Utilization of Pre-trained Language Models**: By integrating pre-trained language models, KeyClass harnesses extensive linguistic knowledge, facilitating the accurate classification of medical terms and phrases found in clinical notes.\n",
        "3. **Data Programming Integration**: KeyClass employs data programming to generate probabilistic labels for training data, significantly reducing the reliance on manually labeled datasets.\n",
        "\n",
        "### 1.2.2 Performance\n",
        "KeyClass demonstrated strong performance across multiple datasets, particularly the MIMIC-III database, where it was tasked with assigning ICD-9 codes to medical notes. It performed comparably to more traditional supervised learning methods such as FasTag <sup><a href=\"#references\"><b>9</b></a></sup>, showcasing its capability to effectively handle real-world, complex text classification tasks without extensive manual data labeling.\n",
        "\n",
        "### 1.2.3 Contribution to Research\n",
        "KeyClass significantly contributes to the field by addressing the high costs and labor-intensive processes involved in manual ICD code assignment. It provides a scalable and efficient solution that could be adopted widely in healthcare settings to enhance the accuracy and efficiency of medical coding practices. The model's ability to perform well without labeled data presents a significant advancement in machine learning applications within the healthcare sector, offering a pathway toward more automated and accessible medical record management systems. This approach not only aligns with the ongoing needs for improved data handling in healthcare but also sets a foundation for future research in automated systems that require minimal human intervention while maintaining high accuracy and reliability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "# 2. Scope of Reproducibility\n",
        "\n",
        "The following hypothesis from the original paper will be tested in this reproducibility study:\n",
        "\n",
        "1.  KeyClass outperforms advanced weakly supervised models across various text classification tasks.\n",
        "\n",
        "2. KeyClass can effectively assign ICD-9 codes to\n",
        "patient discharge notes without access to labeled documents and minimal human intervention, and performs comparably to robust supervised learning models.\n",
        "\n",
        "3. Automatically generated weak supervision sources (keywords and phrases) from class-label descriptions significantly contribute to the model's performance.\n",
        "\n",
        "## 2.1 Corresponding Experiments\n",
        "\n",
        "1. Experiment for Hypothesis 1:\n",
        "\n",
        "    **Setup:** Evaluate KeyClass on multiple text classification datasets (e.g., AGNews, DBPedia, IMDb, and Amazon Reviews) and compare its accuracy against other weakly supervised models and fully supervised baselines.\n",
        "    \n",
        "    **Expected Outcome:** KeyClass outperforms other weakly supervised models and shows competitive accuracy compared to fully supervised models, proving its generalizability and effectiveness across different types of text classification tasks.\n",
        "\n",
        "2. Experiment for Hypothesis 2:\n",
        "\n",
        "    **Setup:** Use the MIMIC-III database to assess the ability of KeyClass to assign ICD-9 codes to medical discharge notes. Compare the performance metrics (precision, recall, and F1 score) of KeyClass against a robust supervised model that uses manually annotated data.\n",
        "    \n",
        "    **Expected Outcome:** KeyClass achieves performance metrics comparable to those of the supervised model, demonstrating its efficacy in a real-world medical dataset without the need for labeled training data.\n",
        "\n",
        "\n",
        "3. Experiment for Hypothesis 3:\n",
        "\n",
        "    **Setup:** Perform ablation studies to measure the impact of automatically generated weak supervision sources on the overall performance of KeyClass. Compare models trained with and without these weak supervision sources.\n",
        "\n",
        "    **Expected Outcome:** Models utilizing automatically generated weak supervision sources perform better than those without, indicating the importance of these sources in achieving high classification accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "# 3. Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeFPUSlKvUBk"
      },
      "source": [
        "## 3.1 Hypothesis 1\n",
        "\n",
        "### 3.1.1 Data\n",
        "\n",
        "**Source and Nature of Data:**\n",
        "\n",
        "The datasets used for evaluating the KeyClass model in the original paper include AGNews, DBPedia, IMDb, and Amazon Reviews. These are publicly available text classification datasets widely utilized in the machine learning community for benchmarking text classification models.\n",
        "\n",
        "- **AGNews:** Comprises news articles categorized into four classes, used to evaluate the model's performance on news topic classification.\n",
        "- **DBPedia:** Contains Wikipedia articles categorized into several classes, used to test the model's ability to classify encyclopedic entries effectively.\n",
        "- **IMDb:** Consists of movie reviews labeled as positive or negative, providing a basis for sentiment analysis.\n",
        "- **Amazon Reviews:** Includes product reviews similarly labeled as positive or negative, used for sentiment classification.\n",
        "\n",
        "**Dataset Access and Preparation:**\n",
        "The original paper's repository included pre-processed data as per the requirements of the KeyClass model. The data included the class descriptions, in the corresponding config files, and labels generated using KeyClass. In order to accomodate the constrained compuational resources of a typical consumer-grade laptop (MacBook Air Apple M2, 2022, 24 GB RAM), we did not re-process this data.\n",
        "\n",
        "\n",
        "### 3.1.2 Model\n",
        "\n",
        "**Model Setup and Architecture:**\n",
        "The evaluation uses pre-trained KeyClass models, weakly supervised text classification frameworks that integrates with `paraphrase-mpnet-base-v2`.\n",
        "\n",
        "**Layers and Activation Functions:** The model employs multiple layers, typically including an embedding layer followed by several transformation layers, with LeakyReLU activations to introduce non-linearity.  \n",
        "\n",
        "**Training Objectives:** The model uses a cross-entropy loss which measures the performance of a classification model whose output is a probability value between 0 and 1.\n",
        "\n",
        "**Pre-trained Model Evaluation:**\n",
        "The pre-trained KeyClass model provided in the repository will be used for evaluation. No re-training of the model will be conducted to ensure the results are solely based on the pre-trained parameters, providing insights into the model’s out-of-the-box effectiveness.  \n",
        "\n",
        "**Computational Constraints:**\n",
        "\n",
        "**Hardware Used:** The evaluations will be conducted on a MacBook Air with an Apple M2 chip and 24 GB of RAM. This setup is significantly less powerful than the computing clusters mentioned in the original study, potentially affecting the speed and scalability of the model evaluations.  \n",
        "\n",
        "**Performance Metrics:** Key metrics such as accuracy, precision, and recall will be calculated to assess the model's performance across different datasets and compared with the published results.\n",
        "This structured approach will ensure a clear and systematic evaluation of the pre-trained KeyClass model against various text classification tasks under the constrained computational resources of a typical consumer-grade laptop.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IMDB Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6SzY39NDAls"
      },
      "source": [
        "***Our Goal here is to first to try and reproduce the results. Starter code for this is provided in the original repository. We will then try to run the model on a the dataset is hope to get similar results as the original paper.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Find Relevant Keywords / Encoding the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3oKMbexNCd9A"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/beast/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('../keyclass/')\n",
        "sys.path.append('../scripts/')\n",
        "\n",
        "import argparse\n",
        "import label_data, encode_datasets, train_downstream_model\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "from os.path import join, exists\n",
        "from datetime import datetime\n",
        "import utils\n",
        "import models\n",
        "import create_lfs\n",
        "import train_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: TOKENIZERS_PARALLELISM=True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%env TOKENIZERS_PARALLELISM=True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA DEVICES:\n",
            "Tokenizers Parallel: True\n"
          ]
        }
      ],
      "source": [
        "!echo \"CUDA DEVICES:\" $CUDA_VISIBLE_DEVICES\n",
        "!echo \"Tokenizers Parallel:\" $TOKENIZERS_PARALLELISM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tC4l5GIrC_k2"
      },
      "outputs": [],
      "source": [
        "# Input arguments\n",
        "config_file_path = r'../config_files/config_imdb.yml' # Specify path to the configuration file\n",
        "random_seed = 0 # Random seed for experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-mpnet-base-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "317455749b444d4f8860930e8d39367e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/196 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4afe0be5e7fd496fb23c7eb5719e44f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/196 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "args = utils.Parser(config_file_path=config_file_path).parse()\n",
        "\n",
        "if args['use_custom_encoder']:\n",
        "    model = models.CustomEncoder(pretrained_model_name_or_path=args['base_encoder'], \n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "else:\n",
        "    model = models.Encoder(model_name=args['base_encoder'], \n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for split in ['train', 'test']:\n",
        "    sentences = utils.fetch_data(dataset=args['dataset'], split=split, path=args['data_path'])\n",
        "    embeddings = model.encode(sentences=sentences, batch_size=args['end_model_batch_size'], \n",
        "                                show_progress_bar=args['show_progress_bar'], \n",
        "                                normalize_embeddings=args['normalize_embeddings'])\n",
        "    with open(join(args['data_path'], args['dataset'], f'{split}_embeddings.pkl'), 'wb') as f:\n",
        "        pickle.dump(embeddings, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Probabilistically Labeling the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-mpnet-base-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting labels for the imdb data...\n",
            "Size of the data: 25000\n",
            "Class distribution (array([0, 1]), array([12500, 12500]))\n",
            "Found assigned category counts [6789 9578]\n",
            "labeler.vocabulary:\n",
            " 16367\n",
            "labeler.word_indicator_matrix.shape (25000, 600)\n",
            "Len keywords 600\n",
            "assigned_category: Unique and Counts (array([0, 1]), array([300, 300]))\n",
            "negative, hate, expensive, bad, poor, broke, waste, horrible, would not recommend ['abominable' 'abomination' 'absolute worst' 'absolutely awful'\n",
            " 'absolutely terrible' 'abuse' 'abused' 'abusive' 'abysmal'\n",
            " 'acting horrible' 'acting poor' 'acting terrible' 'actors bad'\n",
            " 'actually bad' 'also bad' 'among worst' 'annoyance' 'annoying' 'appalled'\n",
            " 'appalling' 'atrocious' 'awful' 'awfully' 'awfulness' 'bad' 'bad actor'\n",
            " 'bad actors' 'bad actually' 'bad almost' 'bad bad' 'bad could'\n",
            " 'bad either' 'bad enough' 'bad even' 'bad film' 'bad films' 'bad get'\n",
            " 'bad horror' 'bad idea' 'bad like' 'bad made' 'bad makes' 'bad many'\n",
            " 'bad movie' 'bad movies' 'bad music' 'bad one' 'bad ones' 'bad people'\n",
            " 'bad really' 'bad reviews' 'bad special' 'bad story' 'bad taste'\n",
            " 'bad thing' 'bad things' 'bad think' 'bad way' 'bad well' 'bad would'\n",
            " 'baddies' 'badly' 'badly made' 'badness' 'best worst' 'better worse'\n",
            " 'big disappointment' 'chose' 'complain' 'complained' 'complaining'\n",
            " 'complains' 'crap like' 'crappy' 'criticism' 'criticisms' 'criticize'\n",
            " 'criticized' 'cursed' 'cursing' 'cynical' 'cynicism' 'depressed'\n",
            " 'depressing' 'despair' 'desperation' 'despicable' 'despise'\n",
            " 'disappointed' 'disappointing' 'disappointment' 'disastrous' 'disdain'\n",
            " 'disgust' 'disgusted' 'disgusting' 'dislike' 'disliked' 'dismal'\n",
            " 'displeasure' 'distasteful' 'distraught' 'dreaded' 'dreadful'\n",
            " 'dreadfully' 'easily worst' 'else say' 'even bad' 'even worst'\n",
            " 'far worse' 'far worst' 'feel bad' 'feel sorry' 'film awful' 'film bad'\n",
            " 'film terrible' 'film worst' 'films bad' 'filth' 'filthy' 'get bad'\n",
            " 'god awful' 'greed' 'hapless' 'hate' 'hate film' 'hate movie' 'hated'\n",
            " 'hated movie' 'hateful' 'hates' 'hating' 'hatred' 'hideous' 'hideously'\n",
            " 'honestly say' 'horrendous' 'horrible' 'horrible film' 'horrible movie'\n",
            " 'horribly' 'horrid' 'horrific' 'huge disappointment' 'humble opinion'\n",
            " 'idiotic' 'immoral' 'incredibly bad' 'incredibly stupid' 'irresponsible'\n",
            " 'know bad' 'lack' 'lackluster' 'laughably bad' 'least good' 'like bad'\n",
            " 'like cheap' 'like horror' 'like least' 'like say' 'loathing' 'lot bad'\n",
            " 'lousy' 'love bad' 'love hate' 'low quality' 'made bad'\n",
            " 'major disappointment' 'make bad' 'many bad' 'mean spirited' 'mediocrity'\n",
            " 'miserable' 'miserably' 'misery' 'misfortune' 'misguided' 'movie awful'\n",
            " 'movie bad' 'movie horrible' 'movie terrible' 'movie worst' 'movies bad'\n",
            " 'much worse' 'nasty' 'needless say' 'needlessly' 'negative comments'\n",
            " 'negative reviews' 'never want' 'nothing good' 'notorious' 'one awful'\n",
            " 'one bad' 'one worst' 'opinion' 'opinions' 'pathetic' 'people hate'\n",
            " 'pity' 'plain awful' 'plain bad' 'plain stupid' 'poor' 'poor quality'\n",
            " 'poorest' 'poorly' 'possibly worst' 'poverty' 'pretty awful' 'pretty bad'\n",
            " 'pretty lame' 'pretty poor' 'probably worst' 'quite bad' 'rather poor'\n",
            " 'really annoying' 'really awful' 'really bad' 'really disappointed'\n",
            " 'really hate' 'really poor' 'really sad' 'really stupid'\n",
            " 'really terrible' 'refuse' 'regret' 'regrets' 'reject' 'repulsive'\n",
            " 'rotten' 'sad' 'sad thing' 'saddest' 'sadistic' 'sadly' 'sadness'\n",
            " 'say bad' 'say worst' 'see bad' 'seedy' 'simply awful' 'something bad'\n",
            " 'still bad' 'story bad' 'stupid' 'stupidest' 'stupidity' 'stupidly'\n",
            " 'sucks' 'terrible' 'terrible film' 'terrible movie' 'terribly'\n",
            " 'think bad' 'tiresome' 'trash' 'trashy' 'truly awful' 'truly bad' 'ugly'\n",
            " 'unappealing' 'unattractive' 'unbearably' 'uneducated' 'unfortunate'\n",
            " 'unfortunately' 'unfortunately film' 'unhappy' 'unimaginative'\n",
            " 'unimpressive' 'uninteresting' 'unlikable' 'unlikeable' 'unlucky'\n",
            " 'unnecessarily' 'unpleasant' 'unrealistic' 'unremarkable' 'unsatisfied'\n",
            " 'unsatisfying' 'unsympathetic' 'unwilling' 'waste money' 'worse'\n",
            " 'worse movie' 'worse movies' 'worst' 'worst acting' 'worst ever'\n",
            " 'worst film' 'worst films' 'worst kind' 'worst movie' 'worst movies'\n",
            " 'worst part' 'worst thing' 'worthless' 'wretched' 'writing bad']\n",
            "good, positive, excellent, amazing, love, fine, good quality, would recommend ['actually good' 'actually like' 'admirable' 'admirably' 'admired'\n",
            " 'almost good' 'also enjoyed' 'also excellent' 'also good' 'also great'\n",
            " 'also interesting' 'also like' 'also liked' 'also nice' 'also pretty'\n",
            " 'also well' 'always good' 'always great' 'among best' 'another good'\n",
            " 'another great' 'another reviewer' 'anyone likes' 'anything good'\n",
            " 'award best' 'bad good' 'best' 'best best' 'best ever' 'best one'\n",
            " 'best parts' 'best performance' 'best show' 'best thing' 'best things'\n",
            " 'better ones' 'certainly good' 'commendable' 'damn good'\n",
            " 'definitely good' 'definitely recommend' 'definitely worth' 'done good'\n",
            " 'done great' 'enjoy' 'enjoy good' 'enjoyable' 'enjoyable film'\n",
            " 'enjoyable movie' 'enjoyable watch' 'enough good' 'entertainment value'\n",
            " 'especially good' 'especially like' 'especially liked' 'even good'\n",
            " 'even great' 'excellence' 'excellent' 'excellent film' 'excellent job'\n",
            " 'excellent movie' 'excellent performance' 'excellent performances'\n",
            " 'excellently' 'exquisite' 'extremely well' 'fabulous' 'fairly good'\n",
            " 'fantastic' 'far best' 'film excellent' 'find good' 'fine job'\n",
            " 'fine performances' 'finest' 'first rate' 'get good' 'give good'\n",
            " 'gives best' 'gives good' 'gives great' 'good' 'good action' 'good also'\n",
            " 'good although' 'good bad' 'good choice' 'good direction' 'good either'\n",
            " 'good enough' 'good entertainment' 'good especially' 'good even'\n",
            " 'good example' 'good film' 'good films' 'good first' 'good good'\n",
            " 'good great' 'good idea' 'good movie' 'good music' 'good one' 'good ones'\n",
            " 'good original' 'good part' 'good parts' 'good people' 'good performance'\n",
            " 'good performances' 'good really' 'good reviews' 'good say' 'good show'\n",
            " 'good special' 'good stuff' 'good taste' 'good thing' 'good things'\n",
            " 'good think' 'good though' 'good tv' 'good use' 'good well' 'good work'\n",
            " 'good would' 'good writing' 'got good' 'got great' 'great'\n",
            " 'great character' 'great example' 'great film' 'great fun' 'great love'\n",
            " 'great music' 'great one' 'great really' 'great show' 'great supporting'\n",
            " 'great things' 'great time' 'greats' 'high quality' 'high rating'\n",
            " 'highly recommend' 'highly recommended' 'however like' 'idea good'\n",
            " 'like best' 'like good' 'like great' 'liked' 'liked one' 'looks great'\n",
            " 'lot good' 'lot great' 'love good' 'lovely' 'luxury' 'made good'\n",
            " 'made great' 'made well' 'make good' 'make great' 'makes good'\n",
            " 'makes great' 'many good' 'many great' 'many reviewers' 'many reviews'\n",
            " 'marvelously' 'may good' 'mean good' 'might good' 'movie excellent'\n",
            " 'movie good' 'movie recommend' 'movie wonderful' 'much enjoyed'\n",
            " 'much good' 'music good' 'music great' 'nearly good' 'nice' 'nice look'\n",
            " 'nothing better' 'one best' 'one finest' 'one good' 'one great'\n",
            " 'one like' 'overall good' 'overall think' 'particularly good'\n",
            " 'people good' 'people like' 'performances good' 'perhaps best'\n",
            " 'personal favorite' 'personally think' 'pleasant' 'positive reviews'\n",
            " 'positive thing' 'possibly best' 'praise' 'prefer' 'prefers'\n",
            " 'pretty decent' 'pretty good' 'probably best' 'probably good'\n",
            " 'probably like' 'put good' 'qualities' 'quality' 'quality acting'\n",
            " 'quite enjoyable' 'quite good' 'quite like' 'rather good' 'rating 10'\n",
            " 'read review' 'read reviews' 'reading reviews' 'real good'\n",
            " 'really appreciate' 'really enjoy' 'really enjoyed' 'really good'\n",
            " 'really great' 'really like' 'really liked' 'really loved' 'really nice'\n",
            " 'really recommend' 'recommend' 'recommend anyone' 'recommend everyone'\n",
            " 'recommend film' 'recommend movie' 'recommend one' 'recommend see'\n",
            " 'recommend watch' 'recommend watching' 'recommendation' 'recommended'\n",
            " 'recommending' 'redeeming quality' 'reviews' 'satisfactory' 'say best'\n",
            " 'say good' 'see good' 'seen good' 'show good' 'solid performances'\n",
            " 'something better' 'something good' 'something interesting' 'splendid'\n",
            " 'still enjoyable' 'still good' 'still great' 'strongly recommend'\n",
            " 'surprisingly good' 'tasteful' 'terrific' 'thing good' 'think best'\n",
            " 'think good' 'think great' 'though good' 'thought good' 'thought great'\n",
            " 'time great' 'top notch' 'truly great' 'two best' 'want good'\n",
            " 'watch good' 'well crafted' 'well good' 'well great' 'well made'\n",
            " 'well produced' 'well worth' 'wonderful' 'wonderful film' 'wonderful job'\n",
            " 'wonderful life' 'wonderful movie' 'wonderfully' 'worth look'\n",
            " 'worth mentioning' 'worth seeing' 'worthwhile' 'would good'\n",
            " 'would recommend']\n",
            "==== Training the label model ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Computing O...\n",
            "INFO:root:Estimating \\mu...\n",
            "INFO:root:Using GPU...\n",
            "  0%|          | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.191]\n",
            "100%|██████████| 100/100 [00:03<00:00, 31.82epoch/s]\n",
            "INFO:root:Finished Training\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Model Predictions: Unique value and counts (array([0, 1]), array([ 8914, 16086]))\n",
            "Label Model Training Accuracy 0.70016\n",
            "Saving results in ../results/imdb/train_label_model_with_ground_truth_19-Apr-2024-00_53_09.txt...\n"
          ]
        }
      ],
      "source": [
        "# Load training data\n",
        "train_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='train')\n",
        "\n",
        "training_labels_present = False\n",
        "if exists(join(args['data_path'], args['dataset'], 'train_labels.txt')):\n",
        "    with open(join(args['data_path'], args['dataset'], 'train_labels.txt'), 'r') as f:\n",
        "        y_train = f.readlines()\n",
        "    y_train = np.array([int(i.replace('\\n','')) for i in y_train])\n",
        "    training_labels_present = True\n",
        "else:\n",
        "    y_train = None\n",
        "    training_labels_present = False\n",
        "    print('No training labels found!')\n",
        "\n",
        "with open(join(args['data_path'], args['dataset'], 'train_embeddings.pkl'), 'rb') as f:\n",
        "    X_train = pickle.load(f)\n",
        "\n",
        "# Print dataset statistics\n",
        "print(f\"Getting labels for the {args['dataset']} data...\")\n",
        "print(f'Size of the data: {len(train_text)}')\n",
        "if training_labels_present:\n",
        "    print('Class distribution', np.unique(y_train, return_counts=True))\n",
        "\n",
        "# Load label names/descriptions\n",
        "label_names = []\n",
        "for a in args:\n",
        "    if 'target' in a: label_names.append(args[a])\n",
        "\n",
        "# Creating labeling functions\n",
        "labeler = create_lfs.CreateLabellingFunctions(base_encoder=args['base_encoder'], \n",
        "                                            device=torch.device(args['device']),\n",
        "                                            label_model=args['label_model'])\n",
        "proba_preds = labeler.get_labels(text_corpus=train_text, label_names=label_names, min_df=args['min_df'], \n",
        "                                ngram_range=args['ngram_range'], topk=args['topk'], y_train=y_train, \n",
        "                                label_model_lr=args['label_model_lr'], label_model_n_epochs=args['label_model_n_epochs'], \n",
        "                                verbose=True, n_classes=args['n_classes'])\n",
        "\n",
        "y_train_pred = np.argmax(proba_preds, axis=1)\n",
        "\n",
        "# Save the predictions\n",
        "if not os.path.exists(args['preds_path']): os.makedirs(args['preds_path'])\n",
        "with open(join(args['preds_path'], f\"{args['label_model']}_proba_preds.pkl\"), 'wb') as f:\n",
        "    pickle.dump(proba_preds, f)\n",
        "\n",
        "# Print statistics\n",
        "print('Label Model Predictions: Unique value and counts', np.unique(y_train_pred, return_counts=True))\n",
        "if training_labels_present:\n",
        "    print('Label Model Training Accuracy', np.mean(y_train_pred==y_train))\n",
        "\n",
        "    # Log the metrics\n",
        "    training_metrics_with_gt = utils.compute_metrics(y_preds=y_train_pred, y_true=y_train, average=args['average'])\n",
        "    utils.log(metrics=training_metrics_with_gt, filename='label_model_with_ground_truth', \n",
        "        results_dir=args['results_path'], split='train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimentation: Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confidence of least confident data point of class 0: 0.9118952182916804\n",
            "Confidence of least confident data point of class 1: 0.9999157388836003\n",
            "\n",
            "==== Data statistics ====\n",
            "Size of training data: (25000, 768), testing data: (25000, 768)\n",
            "Size of testing labels: (25000,)\n",
            "Size of training labels: (25000,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-mpnet-base-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training class distribution (ground truth): [0.5 0.5]\n",
            "Training class distribution (label model predictions): [0.35656 0.64344]\n",
            "\n",
            "KeyClass only trains on the most confidently labeled data points! Applying mask...\n",
            "\n",
            "==== Data statistics (after applying mask) ====\n",
            "Size of training data: (7000, 768)\n",
            "Size of training labels: (7000,)\n",
            "Training class distribution (ground truth): [0.55057143 0.44942857]\n",
            "Training class distribution (label model predictions): [0.5 0.5]\n",
            "\n",
            "===== Training the downstream classifier =====\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17:  85%|████████▌ | 17/20 [00:02<00:00,  6.64batch/s, best_loss=0.543, running_loss=0.547, tolerance_count=3]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stopping early...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "args = utils.Parser(config_file_path=config_file_path).parse()\n",
        "\n",
        "# Set random seeds\n",
        "random_seed = random_seed\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "X_train_embed_masked, y_train_lm_masked, y_train_masked, \\\n",
        "\tX_test_embed, y_test, training_labels_present, \\\n",
        "\tsample_weights_masked, proba_preds_masked = train_downstream_model.load_data(args)\n",
        "\n",
        "# Train a downstream classifier\n",
        "\n",
        "if args['use_custom_encoder']:\n",
        "\tencoder = models.CustomEncoder(pretrained_model_name_or_path=args['base_encoder'], device=args['device'])\n",
        "else:\n",
        "\tencoder = models.Encoder(model_name=args['base_encoder'], device=args['device'])\n",
        "\n",
        "classifier = models.FeedForwardFlexible(encoder_model=encoder,\n",
        "\t\t\t\t\t\t\t\t\t\th_sizes=args['h_sizes'], \n",
        "\t\t\t\t\t\t\t\t\t\tactivation=eval(args['activation']),\n",
        "\t\t\t\t\t\t\t\t\t\tdevice=torch.device(args['device']))\n",
        "print('\\n===== Training the downstream classifier =====\\n')\n",
        "model = train_classifier.train(model=classifier, \n",
        "\t\t\t\t\t\t\tdevice=torch.device(args['device']),\n",
        "\t\t\t\t\t\t\tX_train=X_train_embed_masked, \n",
        "\t\t\t\t\t\t\ty_train=y_train_lm_masked,\n",
        "\t\t\t\t\t\t\tsample_weights=sample_weights_masked if args['use_noise_aware_loss'] else None, \n",
        "\t\t\t\t\t\t\tepochs=args['end_model_epochs'], \n",
        "\t\t\t\t\t\t\tbatch_size=args['end_model_batch_size'], \n",
        "\t\t\t\t\t\t\tcriterion=eval(args['criterion']), \n",
        "\t\t\t\t\t\t\traw_text=False, \n",
        "\t\t\t\t\t\t\tlr=eval(args['end_model_lr']), \n",
        "\t\t\t\t\t\t\tweight_decay=eval(args['end_model_weight_decay']),\n",
        "\t\t\t\t\t\t\tpatience=args['end_model_patience'])\n",
        "\n",
        "\n",
        "end_model_preds_train = model.predict_proba(torch.from_numpy(X_train_embed_masked), batch_size=512, raw_text=False)\n",
        "end_model_preds_test = model.predict_proba(torch.from_numpy(X_test_embed), batch_size=512, raw_text=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Self-Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/62 [00:17<?, ?batch/s]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 7.91 GiB of which 91.56 MiB is free. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 6.90 GiB is allocated by PyTorch, and 302.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mfetch_data(dataset\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m], path\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m'\u001b[39m], split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m X_test_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mfetch_data(dataset\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m], path\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m'\u001b[39m], split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mself_train_lr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mself_train_weight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mself_train_patience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mself_train_batch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mq_update_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mq_update_interval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mself_train_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mself_train_thresh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mprint_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m end_model_preds_test \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_text, batch_size\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_train_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], raw_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Print statistics\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/Deep Learning /Final/KeyClassReproducibility/tutorials/../keyclass/train_classifier.py:231\u001b[0m, in \u001b[0;36mself_train\u001b[0;34m(model, X_train, X_val, y_val, device, lr, weight_decay, batch_size, q_update_interval, patience, self_train_thresh, print_eval)\u001b[0m\n\u001b[1;32m    225\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m X_train[inds][\n\u001b[1;32m    226\u001b[0m     i:i \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    227\u001b[0m     batch_size]  \u001b[38;5;66;03m# The training data is moved to device by the encoder model in its forward function\u001b[39;00m\n\u001b[1;32m    228\u001b[0m batch_q \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(target_dist[i:i \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    229\u001b[0m                                        batch_size])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 231\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mself_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, batch_q)\n\u001b[1;32m    233\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/Documents/Deep Learning /Final/KeyClassReproducibility/tutorials/../keyclass/models.py:314\u001b[0m, in \u001b[0;36mFeedForwardFlexible.forward\u001b[0;34m(self, x, mode, raw_text)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference\u001b[39m\u001b[38;5;124m'\u001b[39m, raw_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw_text:\n\u001b[0;32m--> 314\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m    317\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n",
            "File \u001b[0;32m~/Documents/Deep Learning /Final/KeyClassReproducibility/tutorials/../keyclass/models.py:264\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, sentences, batch_size, show_progress_bar, normalize_embeddings)\u001b[0m\n\u001b[1;32m    260\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtokenize(sentences_batch)\n\u001b[1;32m    261\u001b[0m features \u001b[38;5;241m=\u001b[39m sentence_transformers\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mbatch_to_device(\n\u001b[1;32m    262\u001b[0m     features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 264\u001b[0m out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m out_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize_embeddings:\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m     96\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 98\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:548\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    547\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 548\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    557\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:338\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    336\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 338\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:297\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    290\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    296\u001b[0m ):\n\u001b[0;32m--> 297\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    305\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:238\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    231\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    237\u001b[0m ):\n\u001b[0;32m--> 238\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(self_outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m hidden_states)\n\u001b[1;32m    246\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:187\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 187\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     attention_probs \u001b[38;5;241m=\u001b[39m attention_probs \u001b[38;5;241m*\u001b[39m head_mask\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/torch/nn/functional.py:1268\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 7.91 GiB of which 91.56 MiB is free. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 6.90 GiB is allocated by PyTorch, and 302.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "X_train_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='train')\n",
        "X_test_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='test')\n",
        "\n",
        "model = train_classifier.self_train(model=model, \n",
        "\t\t\t\t\t\t\t\t\tX_train=X_train_text, \n",
        "\t\t\t\t\t\t\t\t\tX_val=X_test_text, \n",
        "\t\t\t\t\t\t\t\t\ty_val=y_test, \n",
        "\t\t\t\t\t\t\t\t\tdevice=torch.device(args['device']), \n",
        "\t\t\t\t\t\t\t\t\tlr=eval(args['self_train_lr']), \n",
        "\t\t\t\t\t\t\t\t\tweight_decay=eval(args['self_train_weight_decay']),\n",
        "\t\t\t\t\t\t\t\t\tpatience=args['self_train_patience'], \n",
        "\t\t\t\t\t\t\t\t\tbatch_size=args['self_train_batch_size'], \n",
        "\t\t\t\t\t\t\t\t\tq_update_interval=args['q_update_interval'],\n",
        "\t\t\t\t\t\t\t\t\tself_train_thresh=eval(args['self_train_thresh']), \n",
        "\t\t\t\t\t\t\t\t\tprint_eval=True)\n",
        "\n",
        "\n",
        "end_model_preds_test = model.predict_proba(X_test_text, batch_size=args['self_train_batch_size'], raw_text=True)\n",
        "\n",
        "\n",
        "# Print statistics\n",
        "testing_metrics = utils.compute_metrics_bootstrap(y_preds=np.argmax(end_model_preds_test, axis=1),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\ty_true=y_test, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\taverage=args['average'], \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tn_bootstrap=args['n_bootstrap'], \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tn_jobs=args['n_jobs'])\n",
        "print(testing_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graphical Representation of the Model  Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  AGNews Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Input arguments\n",
        "config_file_path = r'../config_files/config_agnews.yml' # Specify path to the configuration file\n",
        "random_seed = 0 # Random seed for experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-mpnet-base-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d08d05b1a3914cd7affadbb01a859f8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/938 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71f050ad74dd4627b97f97d8c21f3d97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "args = utils.Parser(config_file_path=config_file_path).parse()\n",
        "\n",
        "if args['use_custom_encoder']:\n",
        "    model = models.CustomEncoder(pretrained_model_name_or_path=args['base_encoder'], \n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "else:\n",
        "    model = models.Encoder(model_name=args['base_encoder'], \n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for split in ['train', 'test']:\n",
        "    sentences = utils.fetch_data(dataset=args['dataset'], split=split, path=args['data_path'])\n",
        "    embeddings = model.encode(sentences=sentences, batch_size=args['end_model_batch_size'], \n",
        "                                show_progress_bar=args['show_progress_bar'], \n",
        "                                normalize_embeddings=args['normalize_embeddings'])\n",
        "    with open(join(args['data_path'], args['dataset'], f'{split}_embeddings.pkl'), 'wb') as f:\n",
        "        pickle.dump(embeddings, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-mpnet-base-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting labels for the agnews data...\n",
            "Size of the data: 120000\n",
            "Class distribution (array([0, 1, 2, 3]), array([30000, 30000, 30000, 30000]))\n",
            "Found assigned category counts [1264  940 1358 1271]\n",
            "labeler.vocabulary:\n",
            " 4833\n",
            "labeler.word_indicator_matrix.shape (120000, 1200)\n",
            "Len keywords 1200\n",
            "assigned_category: Unique and Counts (array([0, 1, 2, 3]), array([300, 300, 300, 300]))\n",
            "politics ['38' '39 decision' '39 president' '42' '45' '46' '54' '56' 'abroad'\n",
            " 'according' 'activists' 'affairs' 'agencies' 'agency' 'agenda' 'allies'\n",
            " 'ambassador' 'america' 'america 39' 'american' 'americans'\n",
            " 'ap ap president' 'ap president' 'approval' 'approve' 'around'\n",
            " 'assassination' 'authorities' 'authority' 'balance' 'ballot' 'ballots'\n",
            " 'battles' 'british prime' 'british prime minister' 'bush' 'bush 39'\n",
            " 'bush administration' 'campaign' 'canada' 'candidate' 'candidates'\n",
            " 'chancellor' 'cheney' 'citizens' 'civilians' 'clashes' 'clinton'\n",
            " 'coalition' 'com washingtonpost' 'com washingtonpost com' 'committee'\n",
            " 'communist' 'conference' 'conflict' 'congress' 'congressional'\n",
            " 'conservative' 'conspiracy' 'controversial' 'controversy' 'convention'\n",
            " 'corruption' 'council' 'countries' 'country' 'country 39' 'coup' 'crisis'\n",
            " 'danger' 'dc' 'debate' 'decide' 'decided' 'decision' 'democracy'\n",
            " 'democrat' 'democratic' 'democrats' 'diplomatic' 'diplomats' 'discuss'\n",
            " 'dispute' 'disputed' 'district' 'dominated' 'draft' 'either' 'elected'\n",
            " 'election' 'elections' 'electoral' 'embassy' 'embattled' 'enforcement'\n",
            " 'eu' 'fact' 'federal' 'federal government' 'fiscal' 'flag' 'following'\n",
            " 'foreign' 'foreign minister' 'foreigners' 'former president' 'gop' 'gov'\n",
            " 'governing' 'government' 'government 39' 'government report'\n",
            " 'government said' 'governments' 'governor' 'govt' 'gt washington post'\n",
            " 'high profile' 'historic' 'history' 'illegal' 'illegally' 'important'\n",
            " 'imposed' 'independence' 'influence' 'insurgency' 'insurgents'\n",
            " 'involvement' 'issue' 'issues' 'john kerry' 'justice' 'kerry' 'law'\n",
            " 'lawmakers' 'laws' 'leader' 'leaders' 'leadership' 'legal' 'legislation'\n",
            " 'lets' 'limits' 'mayor' 'meet' 'meeting' 'meetings' 'members' 'militant'\n",
            " 'militants' 'militia' 'minister' 'minister john' 'minister said'\n",
            " 'minister tony' 'ministers' 'ministry' 'nation' 'nation 39' 'national'\n",
            " 'nations' 'negotiations' 'news' 'next year' 'offense' 'official'\n",
            " 'officially' 'officials' 'officials said' 'officials say' 'opinion'\n",
            " 'opposition' 'opposition leader' 'order' 'overseas' 'pact' 'parliament'\n",
            " 'parliamentary' 'parties' 'party' 'peace process' 'pm' 'pole' 'policies'\n",
            " 'policy' 'political' 'politicians' 'politics' 'poll' 'polls' 'position'\n",
            " 'positions' 'post' 'posts' 'president' 'president george'\n",
            " 'president jacques' 'presidential' 'presidential candidate'\n",
            " 'presidential election' 'presidential elections' 'prime minister'\n",
            " 'prime minister john' 'prime minister tony' 'problems' 'protest'\n",
            " 'protesters' 'protests' 'province' 'public' 'questioned' 'rally' 'ranked'\n",
            " 'ranking' 'ranks' 'recently' 'referendum' 'reform' 'reforms' 'regarding'\n",
            " 'regime' 'regulators' 'relations' 'representatives' 'representing'\n",
            " 'republic' 'republican' 'republicans' 'right' 'rights' 'rule' 'ruled'\n",
            " 'ruling' 'sanctions' 'scandal' 'secretary state' 'security council'\n",
            " 'sen john' 'sen john kerry' 'senate' 'senator' 'sentiment' 'separatist'\n",
            " 'sides' 'since' 'situation' 'social' 'society' 'speculation' 'state'\n",
            " 'states' 'status' 'strategic' 'struggles' 'subject' 'supreme court'\n",
            " 'targeting' 'taxes' 'tensions' 'territory' 'terrorism' 'terrorist'\n",
            " 'terrorists' 'threat' 'threaten' 'threatening' 'threatens' 'threats'\n",
            " 'tony blair' 'tough' 'trouble' 'united states' 'unrest' 'us'\n",
            " 'us government' 'us president' 'us president george' 'usa' 'vice'\n",
            " 'vice president' 'view' 'vote' 'voted' 'voters' 'votes' 'voting' 'war'\n",
            " 'wars' 'washington' 'washington post' 'washington post lt'\n",
            " 'washington reuters' 'washingtonpost' 'washingtonpost com'\n",
            " 'washingtonpost com washingtonpost' 'watch' 'white house' 'whose' 'year']\n",
            "sports ['39 game' 'ability' 'action' 'activities' 'activity' 'aiming'\n",
            " 'american league' 'anaheim angels' 'angeles dodgers' 'arena' 'arsenal'\n",
            " 'astros' 'athens olympics' 'athletes' 'athletic' 'athletics'\n",
            " 'atlanta braves' 'auburn' 'ball' 'ballmer' 'barry bonds' 'baseball'\n",
            " 'baseman' 'basketball' 'bodies' 'boston red' 'boston red sox' 'boxing'\n",
            " 'braves' 'brawl' 'browns' 'buffalo' 'catch' 'cavaliers' 'cbc sports'\n",
            " 'cbc sports online' 'celtics' 'challenge' 'challenges' 'champion'\n",
            " 'champions' 'championship' 'championship series' 'championships' 'chase'\n",
            " 'chicago cubs' 'chiefs' 'classic' 'clemens' 'club' 'coach' 'coaches'\n",
            " 'coaching' 'college football' 'colts' 'comeback' 'compete' 'competing'\n",
            " 'competition' 'competitive' 'competitors' 'conduct' 'contest' 'cowboys'\n",
            " 'crew' 'cricket' 'cubs' 'curt schilling' 'davis cup' 'defender'\n",
            " 'defending champion' 'dick' 'dodgers' 'dolphins' 'doping' 'eagles'\n",
            " 'england patriots' 'entertainment' 'especially' 'espn' 'event' 'events'\n",
            " 'everton' 'f1' 'fair' 'fans' 'federer' 'fenway' 'fenway park' 'field'\n",
            " 'fields' 'fighters' 'fights' 'finals' 'first half' 'first round' 'fit'\n",
            " 'football' 'football association' 'football coach' 'formula one'\n",
            " 'francisco giants' 'fun' 'game' 'game summary' 'gamers' 'games' 'gaming'\n",
            " 'giants' 'goal' 'goals' 'golf' 'grand prix' 'grand slam' 'great'\n",
            " 'gymnastics' 'head coach' 'hitting' 'hockey' 'home run' 'homered'\n",
            " 'houston astros' 'human' 'impressive' 'indiana pacers' 'injuries'\n",
            " 'injury' 'inning' 'innings' 'jersey' 'joint' 'kick' 'knicks'\n",
            " 'last season' 'league' 'league baseball' 'league championship'\n",
            " 'league championship series' 'linebacker' 'lineup' 'los angeles dodgers'\n",
            " 'major league' 'major league baseball' 'marathon' 'mariners' 'marlins'\n",
            " 'match' 'matches' 'medal' 'medals' 'mets' 'miami dolphins'\n",
            " 'michael phelps' 'midfielder' 'minnesota twins' 'montreal expos' 'nascar'\n",
            " 'national league' 'nba' 'ncaa' 'new england' 'new england patriots'\n",
            " 'new york mets' 'new york yankees' 'nfl' 'nhl' 'nintendo' 'notre'\n",
            " 'notre dame' 'olympic' 'olympic committee' 'olympic games' 'olympic gold'\n",
            " 'olympics' 'opponent' 'opponents' 'outfielder' 'pacers' 'packers'\n",
            " 'particularly' 'patriots' 'phelps' 'pitch' 'pitched' 'pitcher' 'pitching'\n",
            " 'play' 'played' 'player' 'players' 'players 39' 'playing' 'playoff'\n",
            " 'playoffs' 'plays' 'pool' 'postseason' 'practice' 'practices'\n",
            " 'premiership' 'preseason' 'pro' 'professional' 'qb' 'quarterback'\n",
            " 'quarterfinals' 'race' 'races' 'racing' 'raiders' 'rangers' 'raptors'\n",
            " 'ravens' 'red sox' 'reds' 'redskins' 'regular season' 'related' 'results'\n",
            " 'ride' 'rival' 'rivalry' 'rivals' 'roger clemens' 'rookie' 'rooney'\n",
            " 'rugby' 'rules' 'run' 'run homer' 'running' 'running back' 'ryder cup'\n",
            " 'san francisco giants' 'score' 'scored' 'scores' 'scoring' 'seahawks'\n",
            " 'season' 'semifinals' 'soccer' 'sox' 'speedway' 'sport' 'sports'\n",
            " 'sports network' 'sports online' 'sprint' 'spurs' 'squad' 'stadium'\n",
            " 'standings' 'steelers' 'striker' 'succeed' 'super bowl' 'swing' 'tackle'\n",
            " 'tampa bay' 'targets' 'team' 'team 39' 'teammates' 'teams' 'tennis'\n",
            " 'three game' 'throwing' 'throws' 'tie' 'tiger' 'tigers' 'titans'\n",
            " 'touchdown' 'touchdowns' 'tournament' 'track' 'training' 'trophy'\n",
            " 'two games' 'two touchdowns' 'uefa' 'used' 'victories' 'vikings'\n",
            " 'white sox' 'wickets' 'wide receiver' 'winners' 'winning'\n",
            " 'winning streak' 'world champion' 'world cup' 'world number one'\n",
            " 'world series' 'xbox' 'yankee' 'yankees' 'york mets' 'york yankees']\n",
            "business ['000' 'account' 'accounting' 'accounts' 'acquire' 'acquisition'\n",
            " 'administration' 'advertising' 'amount' 'antitrust' 'approach' 'asset'\n",
            " 'assets' 'associates' 'auction' 'availability' 'bank' 'banking'\n",
            " 'bankrupt' 'bankruptcy' 'banks' 'became' 'bid' 'bids' 'billion'\n",
            " 'billionaire' 'boss' 'bought' 'brand' 'brands' 'broker' 'brokerage'\n",
            " 'budget' 'building' 'buildings' 'business' 'business software'\n",
            " 'businesses' 'busy' 'buy' 'buyers' 'buying' 'buys' 'called' 'career'\n",
            " 'ceo' 'chief executive' 'chief executive officer' 'claims' 'client'\n",
            " 'clients' 'commerce' 'commercial' 'commission' 'companies'\n",
            " 'companies said' 'company' 'company 39' 'company announced'\n",
            " 'company said' 'company says' 'concerns' 'conducted' 'consumer'\n",
            " 'consumers' 'contract' 'contracts' 'corp' 'corp 39' 'corp said'\n",
            " 'corporate' 'corporation' 'cost' 'costs' 'customer' 'customers' 'deal'\n",
            " 'dealers' 'deals' 'debt' 'demand' 'directors' 'earn' 'earnings'\n",
            " 'economic' 'economic data' 'economic growth' 'economists' 'economy'\n",
            " 'employee' 'employees' 'employers' 'employment' 'enterprise'\n",
            " 'enterprises' 'equity' 'exchange' 'exclusive' 'executive'\n",
            " 'executive officer' 'executives' 'expensive' 'exporters' 'exports'\n",
            " 'factories' 'factory' 'finance' 'financial' 'financial services'\n",
            " 'financing' 'firm' 'firms' 'founder' 'franchise' 'goods' 'group inc'\n",
            " 'growth' 'headquarters' 'high end' 'hire' 'hired' 'hiring' 'holdings'\n",
            " 'however' 'http www investor' 'ibm corp' 'income' 'industries' 'industry'\n",
            " 'initiative' 'interest' 'international business' 'international inc'\n",
            " 'inventories' 'invest' 'investment' 'investment bank' 'investments'\n",
            " 'investor' 'investor reuters' 'investor reuters com' 'investors' 'job'\n",
            " 'jobs' 'joint venture' 'launched' 'license' 'licensing' 'ltd' 'luxury'\n",
            " 'managed' 'management' 'manager' 'managers' 'managing' 'manufacturer'\n",
            " 'manufacturers' 'manufacturing' 'market' 'market share' 'marketing'\n",
            " 'markets' 'mart' 'mart stores' 'mart stores inc' 'merger' 'monetary'\n",
            " 'money' 'net income' 'net profit' 'offer' 'offering' 'offerings' 'offers'\n",
            " 'office' 'offices' 'oil company' 'operating' 'operation' 'operations'\n",
            " 'opportunity' 'orders' 'organisation' 'organization' 'organizations'\n",
            " 'outsourcing' 'owned' 'owner' 'owners' 'partners' 'partnership' 'patent'\n",
            " 'patents' 'percent' 'plc' 'portfolio' 'premier' 'price' 'priced' 'prices'\n",
            " 'pricing' 'privately' 'process' 'producer' 'producers' 'production'\n",
            " 'profit' 'profits' 'proposal' 'proposals' 'prospects' 'provider'\n",
            " 'providers' 'purchase' 'quarter profit' 'quarterly' 'quarterly profit'\n",
            " 'rate' 'rates' 'real estate' 'regulatory' 'reportedly' 'reports'\n",
            " 'research firm' 'responsibility' 'restructuring' 'retail' 'retail sales'\n",
            " 'retailer' 'retailers' 'revenue' 'revenues' 'role' 'sale' 'sales' 'sbc'\n",
            " 'sears' 'sector' 'securities' 'securities exchange' 'sell' 'selling'\n",
            " 'sells' 'service' 'services' 'shareholder' 'shareholders' 'shares'\n",
            " 'shipments' 'shipping' 'shop' 'shoppers' 'shopping' 'sign' 'signs' 'sold'\n",
            " 'spend' 'spending' 'stake' 'stock' 'stock exchange' 'stock market'\n",
            " 'stocks' 'store' 'stores' 'stores inc' 'strategy' 'street' 'subsidiary'\n",
            " 'success' 'supplier' 'supply' 'takeover' 'today' 'town' 'trade'\n",
            " 'trade organization' 'traded' 'traders' 'trading' 'treasury'\n",
            " 'two companies' 'us economy' 'valuable' 'vendor' 'vendors' 'venture'\n",
            " 'wage' 'wal' 'wal mart' 'wal mart stores' 'wall street'\n",
            " 'wall street journal' 'work' 'workers' 'working' 'world trade' 'worth'\n",
            " 'www investor' 'www investor reuters']\n",
            "technology ['2000' '400' 'advance' 'advanced' 'advanced micro'\n",
            " 'advanced micro devices' 'advances' 'advantage' 'alert' 'also'\n",
            " 'amp wireless' 'analyst' 'analysts' 'apple computer' 'apple computer inc'\n",
            " 'application' 'applications' 'auto' 'becomes' 'becoming' 'bit'\n",
            " 'breakthrough' 'broadband' 'browser' 'cable' 'cameras' 'capabilities'\n",
            " 'capable' 'capacity' 'cell phone' 'cell phones' 'cellular' 'century'\n",
            " 'chip' 'chip maker' 'cingular wireless' 'circuit' 'cisco' 'cisco systems'\n",
            " 'com' 'communications' 'communications inc' 'computer'\n",
            " 'computer associates' 'computer inc' 'computer maker' 'computers'\n",
            " 'computerworld' 'computing' 'connection' 'connections'\n",
            " 'consumer electronics' 'current' 'cyber' 'decade' 'decades' 'dell'\n",
            " 'deployment' 'described' 'description' 'design' 'designed' 'desktop'\n",
            " 'develop' 'developed' 'developer' 'developers' 'developing' 'development'\n",
            " 'device' 'devices' 'digital' 'digital music' 'display' 'download'\n",
            " 'downloads' 'drive' 'drives' 'edge' 'electric' 'electricity' 'electronic'\n",
            " 'electronics' 'emerging' 'energy' 'engine' 'engineer' 'engineering'\n",
            " 'engineers' 'engines' 'equipment' 'era' 'everything' 'existing' 'experts'\n",
            " 'explorer' 'facility' 'fashion' 'fast' 'faster' 'fastest' 'feature'\n",
            " 'features' 'film' 'flash' 'format' 'future' 'gear' 'hackers' 'halo'\n",
            " 'handheld' 'handset' 'handsets' 'hardware' 'hd' 'hewlett packard'\n",
            " 'hewlett packard co' 'high speed' 'high tech' 'hp' 'ibm' 'improved'\n",
            " 'improvement' 'improving' 'increasingly' 'industrial' 'info'\n",
            " 'info qcat news' 'information' 'infoworld' 'infrastructure' 'institute'\n",
            " 'instruments' 'integration' 'intel' 'intel corp' 'intelligence'\n",
            " 'internet' 'internet access' 'internet service' 'introduced' 'involving'\n",
            " 'ip' 'ipod' 'ite' 'lab' 'laboratory' 'laptop' 'latest' 'machine'\n",
            " 'machines' 'maker' 'makers' 'material' 'materials' 'media' 'message'\n",
            " 'micro devices' 'microsoft' 'microsystems' 'mobile' 'mobile phone'\n",
            " 'mobile phones' 'modern' 'monitor' 'motor' 'motorola' 'motors' 'mp3'\n",
            " 'nec' 'net' 'network' 'networking' 'networks' 'new version' 'newest'\n",
            " 'newly' 'newratings' 'next generation' 'nextel' 'nextel communications'\n",
            " 'nokia' 'online' 'output' 'package' 'panel' 'pc' 'pc world' 'pc world pc'\n",
            " 'pcs' 'performance' 'personal computer' 'phone' 'phones' 'pioneer'\n",
            " 'platform' 'port' 'portable' 'potential' 'power' 'powered' 'processor'\n",
            " 'processors' 'product' 'products' 'program' 'programme' 'programs'\n",
            " 'progress' 'project' 'projects' 'protocol' 'quality' 'quickly' 'radio'\n",
            " 'rapid' 'rapidly' 'receiver' 'recent' 'recording' 'remote' 'repair'\n",
            " 'research' 'researchers' 'resources' 'revolution' 'samsung' 'science'\n",
            " 'scientific' 'scientist' 'scientists' 'screen' 'semiconductor' 'signal'\n",
            " 'signals' 'silicon' 'smart' 'software' 'software company'\n",
            " 'software giant' 'software maker' 'something' 'spacecraft' 'speed' 'spy'\n",
            " 'spyware' 'stem' 'studio' 'successor' 'supercomputer' 'supplies' 'system'\n",
            " 'systems' 'systems inc' 'tape' 'tech' 'technical' 'technologies'\n",
            " 'technology' 'telecom' 'telecommunications' 'telecoms' 'thing' 'things'\n",
            " 'time warner' 'tool' 'tools' 'transport' 'trend' 'type' 'upcoming'\n",
            " 'update' 'updated' 'updates' 'upgrade' 'use' 'user' 'users' 'uses'\n",
            " 'utility' 'vehicle' 'vehicles' 'verge' 'version' 'versions' 'virtual'\n",
            " 'vodafone' 'voip' 'volume' 'ways' 'web' 'web browser' 'web services'\n",
            " 'website' 'wire' 'wireless' 'works' 'world pc' 'world pc world' 'www']\n",
            "==== Training the label model ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Computing O...\n",
            "INFO:root:Estimating \\mu...\n",
            "INFO:root:Using GPU...\n",
            "  0%|          | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.046]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.71epoch/s]\n",
            "INFO:root:Finished Training\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Model Predictions: Unique value and counts (array([0, 1, 2, 3]), array([37797, 27286, 33806, 21111]))\n",
            "Label Model Training Accuracy 0.7307166666666667\n",
            "Saving results in ../results/agnews/train_label_model_with_ground_truth_18-Apr-2024-22_59_39.txt...\n"
          ]
        }
      ],
      "source": [
        "# Load training data\n",
        "train_text = utils.fetch_data(dataset=args['dataset'], path=args['data_path'], split='train')\n",
        "\n",
        "training_labels_present = False\n",
        "if exists(join(args['data_path'], args['dataset'], 'train_labels.txt')):\n",
        "    with open(join(args['data_path'], args['dataset'], 'train_labels.txt'), 'r') as f:\n",
        "        y_train = f.readlines()\n",
        "    y_train = np.array([int(i.replace('\\n','')) for i in y_train])\n",
        "    training_labels_present = True\n",
        "else:\n",
        "    y_train = None\n",
        "    training_labels_present = False\n",
        "    print('No training labels found!')\n",
        "\n",
        "with open(join(args['data_path'], args['dataset'], 'train_embeddings.pkl'), 'rb') as f:\n",
        "    X_train = pickle.load(f)\n",
        "\n",
        "# Print dataset statistics\n",
        "print(f\"Getting labels for the {args['dataset']} data...\")\n",
        "print(f'Size of the data: {len(train_text)}')\n",
        "if training_labels_present:\n",
        "    print('Class distribution', np.unique(y_train, return_counts=True))\n",
        "\n",
        "# Load label names/descriptions\n",
        "label_names = []\n",
        "for a in args:\n",
        "    if 'target' in a: label_names.append(args[a])\n",
        "\n",
        "# Creating labeling functions\n",
        "labeler = create_lfs.CreateLabellingFunctions(base_encoder=args['base_encoder'], \n",
        "                                            device=torch.device(args['device']),\n",
        "                                            label_model=args['label_model'])\n",
        "proba_preds = labeler.get_labels(text_corpus=train_text, label_names=label_names, min_df=args['min_df'], \n",
        "                                ngram_range=args['ngram_range'], topk=args['topk'], y_train=y_train, \n",
        "                                label_model_lr=args['label_model_lr'], label_model_n_epochs=args['label_model_n_epochs'], \n",
        "                                verbose=True, n_classes=args['n_classes'])\n",
        "\n",
        "y_train_pred = np.argmax(proba_preds, axis=1)\n",
        "\n",
        "# Save the predictions\n",
        "if not os.path.exists(args['preds_path']): os.makedirs(args['preds_path'])\n",
        "with open(join(args['preds_path'], f\"{args['label_model']}_proba_preds.pkl\"), 'wb') as f:\n",
        "    pickle.dump(proba_preds, f)\n",
        "\n",
        "# Print statistics\n",
        "print('Label Model Predictions: Unique value and counts', np.unique(y_train_pred, return_counts=True))\n",
        "if training_labels_present:\n",
        "    print('Label Model Training Accuracy', np.mean(y_train_pred==y_train))\n",
        "\n",
        "    # Log the metrics\n",
        "    training_metrics_with_gt = utils.compute_metrics(y_preds=y_train_pred, y_true=y_train, average=args['average'])\n",
        "    utils.log(metrics=training_metrics_with_gt, filename='label_model_with_ground_truth', \n",
        "        results_dir=args['results_path'], split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confidence of least confident data point of class 0: 0.999973353215707\n",
            "Confidence of least confident data point of class 1: 0.9999247032070704\n",
            "Confidence of least confident data point of class 2: 0.99997263773784\n",
            "Confidence of least confident data point of class 3: 0.9977551330869513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-mpnet-base-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Data statistics ====\n",
            "Size of training data: (120000, 768), testing data: (7600, 768)\n",
            "Size of testing labels: (7600,)\n",
            "Size of training labels: (120000,)\n",
            "Training class distribution (ground truth): [0.25 0.25 0.25 0.25]\n",
            "Training class distribution (label model predictions): [0.314975   0.22738333 0.28171667 0.175925  ]\n",
            "\n",
            "KeyClass only trains on the most confidently labeled data points! Applying mask...\n",
            "\n",
            "==== Data statistics (after applying mask) ====\n",
            "Size of training data: (14000, 768)\n",
            "Size of training labels: (14000,)\n",
            "Training class distribution (ground truth): [0.24078571 0.24357143 0.2575     0.25814286]\n",
            "Training class distribution (label model predictions): [0.25 0.25 0.25 0.25]\n",
            "\n",
            "===== Training the downstream classifier =====\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19:  95%|█████████▌| 19/20 [00:08<00:00,  2.26batch/s, best_loss=1.08, running_loss=1.08, tolerance_count=3]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stopping early...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "args = utils.Parser(config_file_path=config_file_path).parse()\n",
        "\n",
        "# Set random seeds\n",
        "random_seed = random_seed\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "X_train_embed_masked, y_train_lm_masked, y_train_masked, \\\n",
        "\tX_test_embed, y_test, training_labels_present, \\\n",
        "\tsample_weights_masked, proba_preds_masked = train_downstream_model.load_data(args)\n",
        "\n",
        "# Train a downstream classifier\n",
        "\n",
        "if args['use_custom_encoder']:\n",
        "\tencoder = models.CustomEncoder(pretrained_model_name_or_path=args['base_encoder'], device=args['device'])\n",
        "else:\n",
        "\tencoder = models.Encoder(model_name=args['base_encoder'], device=args['device'])\n",
        "\n",
        "classifier = models.FeedForwardFlexible(encoder_model=encoder,\n",
        "\t\t\t\t\t\t\t\t\t\th_sizes=args['h_sizes'], \n",
        "\t\t\t\t\t\t\t\t\t\tactivation=eval(args['activation']),\n",
        "\t\t\t\t\t\t\t\t\t\tdevice=torch.device(args['device']))\n",
        "print('\\n===== Training the downstream classifier =====\\n')\n",
        "model = train_classifier.train(model=classifier, \n",
        "\t\t\t\t\t\t\tdevice=torch.device(args['device']),\n",
        "\t\t\t\t\t\t\tX_train=X_train_embed_masked, \n",
        "\t\t\t\t\t\t\ty_train=y_train_lm_masked,\n",
        "\t\t\t\t\t\t\tsample_weights=sample_weights_masked if args['use_noise_aware_loss'] else None, \n",
        "\t\t\t\t\t\t\tepochs=args['end_model_epochs'], \n",
        "\t\t\t\t\t\t\tbatch_size=args['end_model_batch_size'], \n",
        "\t\t\t\t\t\t\tcriterion=eval(args['criterion']), \n",
        "\t\t\t\t\t\t\traw_text=False, \n",
        "\t\t\t\t\t\t\tlr=eval(args['end_model_lr']), \n",
        "\t\t\t\t\t\t\tweight_decay=eval(args['end_model_weight_decay']),\n",
        "\t\t\t\t\t\t\tpatience=args['end_model_patience'])\n",
        "\n",
        "\n",
        "end_model_preds_train = model.predict_proba(torch.from_numpy(X_train_embed_masked), batch_size=512, raw_text=False)\n",
        "end_model_preds_test = model.predict_proba(torch.from_numpy(X_test_embed), batch_size=512, raw_text=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Matplotlib requires numpy>=1.20; you have 1.19.5",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/seaborn/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import seaborn objects\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcmod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/seaborn/rcmod.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Control plot style and scaling using the matplotlib rcParams interface.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m palettes\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/matplotlib/__init__.py:227\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 227\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_handler\u001b[39m():\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/matplotlib/__init__.py:223\u001b[0m, in \u001b[0;36m_check_versions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(modname)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mImportError\u001b[0m: Matplotlib requires numpy>=1.20; you have 1.19.5"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = {}\n",
        "\n",
        "args = utils.Parser(config_file_path=config_file_path).parse()\n",
        "file_paths = [os.path.join(args['results_path'], f) for f in os.listdir(args['results_path']) if f.endswith('.txt') and ('train_label'or 'train_end')in f]\n",
        "\n",
        "print(file_paths)\n",
        "\n",
        "for file_path in file_paths:\n",
        "\n",
        "    file_name = os.path.basename(file_path)\n",
        "\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = json.load(f)\n",
        "\n",
        "    data[file_name] = content\n",
        "\n",
        "plot_data = []\n",
        "for key, value in data.items():\n",
        "    plot_data.append([key, value['Accuracy'], value['Precision'], value['Recall']])\n",
        "\n",
        "df = pd.melt(pd.DataFrame(plot_data, columns=['Experiment', 'Accuracy', 'Precision', 'Recall']),\n",
        "             id_vars=['Experiment'], value_vars=['Accuracy', 'Precision', 'Recall'],\n",
        "             var_name='Metric', value_name='Value')\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.barplot(x='Experiment', y='Value', hue='Metric', data=df)\n",
        "\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='right')\n",
        "\n",
        "\n",
        "ax.set_xlabel('Experiment')\n",
        "ax.set_ylabel('Value')\n",
        "ax.set_title('Performance Metrics')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Input arguments\n",
        "config_file_path = r'../config_files/config_imdb.yml' # Specify path to the configuration file\n",
        "random_seed = 0 # Random seed for experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Matplotlib requires numpy>=1.20; you have 1.19.5",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/seaborn/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import seaborn objects\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcmod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/seaborn/rcmod.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Control plot style and scaling using the matplotlib rcParams interface.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m palettes\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/matplotlib/__init__.py:227\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 227\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_handler\u001b[39m():\n",
            "File \u001b[0;32m~/anaconda3/envs/keyclass/lib/python3.8/site-packages/matplotlib/__init__.py:223\u001b[0m, in \u001b[0;36m_check_versions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(modname)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mImportError\u001b[0m: Matplotlib requires numpy>=1.20; you have 1.19.5"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = {}\n",
        "\n",
        "args = utils.Parser(config_file_path=config_file_path).parse()\n",
        "file_paths = [os.path.join(args['results_path'], f) for f in os.listdir(args['results_path']) if f.endswith('.txt') and ('train_label'or 'train_end')in f]\n",
        "\n",
        "print(file_paths)\n",
        "\n",
        "for file_path in file_paths:\n",
        "\n",
        "    file_name = os.path.basename(file_path)\n",
        "\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = json.load(f)\n",
        "\n",
        "    data[file_name] = content\n",
        "\n",
        "plot_data = []\n",
        "for key, value in data.items():\n",
        "    plot_data.append([key, value['Accuracy'], value['Precision'], value['Recall']])\n",
        "\n",
        "df = pd.melt(pd.DataFrame(plot_data, columns=['Experiment', 'Accuracy', 'Precision', 'Recall']),\n",
        "             id_vars=['Experiment'], value_vars=['Accuracy', 'Precision', 'Recall'],\n",
        "             var_name='Metric', value_name='Value')\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.barplot(x='Experiment', y='Value', hue='Metric', data=df)\n",
        "\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='right')\n",
        "\n",
        "\n",
        "ax.set_xlabel('Experiment')\n",
        "ax.set_ylabel('Value')\n",
        "ax.set_title('Performance Metrics')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mVOEGs1vcNK"
      },
      "source": [
        "## 3.2 Hypothesis 2\n",
        "\n",
        "### 3.2.1 Data\n",
        "\n",
        "**Source and Nature of Data:**\n",
        "\n",
        "We will be using the MIMIC-III data from Physionet as per the original paper to evaluating KeyClass's ability to assign ICD 9 Codes <sup><a href=\"#references\"><b>11</b></a>,</sup><sup><a href=\"#references\"><b>12</b></a>,</sup><sup><a href=\"#references\"><b>13</b></a></sup>. This data has been downloaded and processed into local PostgreSQL tables. In order to create class descriptions, we will be using a processed version of ICD-9 long descriptions<sup><a href=\"#references\"><b>14</b></a></sup> to find the keywords and phrases.\n",
        "\n",
        "While KeyClass does not require text to be pre-processed, we will follow the original paper's method of preprocessing and keeping only the most useful part of the text in each patient's discharge notes as ranked by TF-IDF statistic.\n",
        "\n",
        "### 3.2.2 Model\n",
        "\n",
        "**Model Setup and Architecture:**\n",
        "For the MIMIC III dataset evaluation, we employ the KeyClass framework, a weakly supervised text classification model that utilizes pre-trained language models enriched with automatically generated weak supervision signals from class-label descriptions. This approach aims to assign ICD-9 codes to discharge summaries within the dataset as described above.This wil be used with BlueBERT, as described in the study.\n",
        "\n",
        "**Layers and Activation Functions:**\n",
        "The downstream classifier comprises a neural encoder followed by a 4-layer Multilayer Perceptron (MLP). Each layer in the MLP utilizes LeakyReLU activation functions to introduce non-linearity. Post each linear layer, a dropout layer with a dropout probability of 0.5 is applied to prevent overfitting.\n",
        "\n",
        "**Training Objectives**\n",
        "The primary training objective is to assign ICD-9 codes to clinical notes effectively. We will utilize binary cross-entropy with logits loss for training the multilabel classification model, which handles multiple labels for each input instance.\n",
        "\n",
        "**Computational Constraints:**\n",
        "**Hardware Used:** To accomodate the compational constraints of working with a typical consumer-grade laptop, we will be utilizing GCP to complete the training and analysis.\n",
        "\n",
        "**Performance Metrics:**\n",
        "Precision, recall, and F1 scores will be calculated, with F1 scores calculated for each of the 19 diagnostic categories. These metrics will help assess the effectiveness of the weakly supervised approach in a multilabel setting and compare it against baseline supervised models. This method will replicate what was done in the paper.\n",
        "\n",
        "**Training Details:**\n",
        "The model will be trained using PyTorch 1.8.1 on Python 3.8.1. The training will involve a batch size of 128 and a maximum of 20 epochs with early stopping enabled if there is no improvement in validation loss after 2 consecutive epochs. The Adam optimizer is used with a learning rate of 0.0015."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6bCcZNuxmz"
      },
      "source": [
        "# Results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ePJl9OLHKwM"
      },
      "source": [
        "We do not yet have any preliminary results. Due to the challenges of working with a typical consumer-grade laptop, we were unable to complete even the evaluation of the pretrained models. Notably, we found that the study results were not reproducible for either Amazon or DBPedia datasets. The original labels, training and test data, and any other information were corrupted or otherwise irretreivable. We have begun transitioning our code into GCP and will be relying on this resource for future progress. We've included a screenshot of our struggles with training below.\n",
        "\n",
        "As outlined above, we will compare the results of the pretrained model against the existing results provided in the repository for Hypothesis 1. Similarly, we will compare our trained model of the MIMIC III dataset to the given metrics in the original paper. As we are not planning on running any of the other models cited in the original paper, such as FasTag <sup><a href=\"#references\"><b>9</b></a></sup>, we will be using the cited metrics to visually compare differences. As we will be calculating F1 scores for each ICD 9 high-level category or chapter, this will still offer a meaningful comparison against the results provided in the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0iXAnKeH6eS"
      },
      "source": [
        "![Screenshot from 2024-04-14 23-59-04.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMI2chl9omn"
      },
      "source": [
        "<a id='references'></a>\n",
        "# 5. References\n",
        "\n",
        "[[1](https://pubmed.ncbi.nlm.nih.gov/16178999/)] O’Malley KJ, Cook KF, Price MD, Wildes KR, Hurdle JF, Ashton CM. Measuring diagnoses: ICD code accuracy. Health Serv Res. 2005 Oct;40(5 Pt 2):1620-39. doi: 10.1111/j.1475-6773.2005.00444.x. PMID: 16178999; PMCID: PMC1361216.\n",
        "\n",
        "[[2](https://pubmed.ncbi.nlm.nih.gov/12711737/)] Calle EE, Rodriguez C, Walker-Thurmond K, Thun MJ. \"Overweight, Obesity, and Mortality from Cancer in a Prospectively Studied Cohort of U.S. Adults.\" New England Journal of Medicine. 2003;348(17):1625–38.\n",
        "\n",
        "[[3](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1475-6773.2005.00444.x)] Charbonneau A, Rosen AK, Ash AS, Owen RR, Kader B, Spiro A, Hankin C, Herz LR, Pugh MJV, Kazis L, Miller DR, Berlowitz DR. \"Measuring the Quality of Depression in a Large Integrated Health System.\" Medical Care. 2003;41:669–80.\n",
        "\n",
        "[[4](https://jamanetwork.com/journals/jama/fullarticle/195992)] Studdert DM, Gresenz CR. \"Enrollee Appeals of Preservice Coverage Denials at 2 Health Maintenance Organizations.\" Journal of the American Medical Association. 2003;289(7):864–70.\n",
        "\n",
        "[[5](https://n.neurology.org/content/49/3/660.short)] Curtis Benesch, DM Witter, AL Wilder, PW Duncan, GP Samsa, and DB Matchar. Inaccuracy of the international classification of diseases (icd-9-cm) in identifying the diagnosis of ischemic cerebrovascular disease. Neurology, 49(3):660–664, 1997.\n",
        "\n",
        "[[6](https://doi.org/10.1186/s12911-021-01531-9)] Wabe N, Li L, Lindeman R, et al. Evaluation of the accuracy of diagnostic coding for influenza compared to laboratory results: the availability of test results before hospital discharge facilitates improved coding accuracy. BMC Med Inform Decis Mak 21, 168 (2021).\n",
        "\n",
        "[[7](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-024-02449-8)] Guo LL, Morse KE, Aftandilian C, Steinberg E, Fries J, Posada J, Fleming SL, Lemmon J, Jessa K, Shah N, Sung L. Characterizing the limitations of using diagnosis codes in the context of machine learning for healthcare. BMC Med Inform Decis Mak. 2024 Feb 14;24(1):51. doi: 10.1186/s12911-024-02449-8. PMID: 38355486; PMCID: PMC10868117.\n",
        "\n",
        "[[8](https://pubmed.ncbi.nlm.nih.gov/28595574/)] Burles K, Innes G, Senior K, Lang E, McRae A. Limitations of pulmonary embolism ICD-10 codes in emergency department administrative data: let the buyer beware. BMC Med Res Methodol. 2017;17(1):89. doi: 10.1186/s12874-017-0361-1.\n",
        "\n",
        "[[9](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0234647)] Venkataraman GR, Pineda AL, Bear Don't Walk Iv OJ, Zehnder AM, Ayyar S, Page RL, Bustamante CD, Rivas MA. FasTag: Automatic text classification of unstructured medical narratives. PLoS One. 2020 Jun 22;15(6):e0234647. doi: 10.1371/journal.pone.0234647. PMID: 32569327; PMCID: PMC7307763.\n",
        "\n",
        "[[10](https://ui.adsabs.harvard.edu/abs/2022arXiv220612088G)]Gao C, Goswami M, Chen J, Dubrawski A. Classifying unstructured clinical notes via automatic weak supervision. arXiv. 2022 Jun [cited 2024 Mar 15]. In: arXiv:2206.12088 [cs.CL]. doi: 10.48550/arXiv.2206.12088.\n",
        "\n",
        "[[11](https://doi.org/10.13026/C2XW26.)]Johnson, A., Pollard, T., & Mark, R. (2016). MIMIC-III Clinical Database (version 1.4). PhysioNet. https://doi.org/10.13026/C2XW26.\n",
        "\n",
        "[[12](https://www.nature.com/articles/sdata201635)]Johnson, A. E. W., Pollard, T. J., Shen, L., Lehman, L. H., Feng, M., Ghassemi, M., Moody, B., Szolovits, P., Celi, L. A., & Mark, R. G. (2016). MIMIC-III, a freely accessible critical care database. Scientific Data, 3, 160035.\n",
        "\n",
        "[[13]() Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215–e220.]\n",
        "\n",
        "[[14](https://github.com/drobbins/ICD9/tree/master)]Robbins D. ICD9 [Internet]. GitHub; 2013. [updated 2013 Nov 11; cited 2024 Apr 14]. Available from: https://github.com/drobbins/ICD9/tree/master"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
